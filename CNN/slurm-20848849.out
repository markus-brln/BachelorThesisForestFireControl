
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

Overview of modules that are loaded
starting CNN
2021-07-01 09:58:35.333302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
--------------------------------------------------------------------------
[[4369,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: pg-gpu17

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
2021-07-01 09:58:45.365654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-07-01 09:58:45.397304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.397641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 32.00GiB deviceMemoryBandwidth: 836.37GiB/s
2021-07-01 09:58:45.397705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 09:58:45.402749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 09:58:45.406229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-07-01 09:58:45.407898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-07-01 09:58:45.411308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-07-01 09:58:45.413363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-07-01 09:58:45.419260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-07-01 09:58:45.419521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.419878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.420081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-07-01 09:58:45.423155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.423412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 32.00GiB deviceMemoryBandwidth: 836.37GiB/s
2021-07-01 09:58:45.423469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 09:58:45.423504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 09:58:45.423525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-07-01 09:58:45.423565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-07-01 09:58:45.423585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-07-01 09:58:45.423605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-07-01 09:58:45.423624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-07-01 09:58:45.423733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.424036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:45.424239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-07-01 09:58:45.424286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 09:58:46.015552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 09:58:46.015649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2021-07-01 09:58:46.015666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2021-07-01 09:58:46.015962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:46.016314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:46.016642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 09:58:46.016875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2021-07-01 09:58:46.017206: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
2021-07-01 09:58:47.892850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 09:58:48.166074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
loading data
input images:  (1435, 256, 256, 7)
outputs:  (1435, 3)
STOCHASTIC run: 0
Train on 1068 samples, validate on 267 samples
Epoch 1/100
1068/1068 - 4s - loss: 0.4628 - mse: 0.4628 - val_loss: 0.1939 - val_mse: 0.1939
Epoch 2/100
1068/1068 - 1s - loss: 0.1933 - mse: 0.1933 - val_loss: 0.1886 - val_mse: 0.1886
Epoch 3/100
1068/1068 - 1s - loss: 0.1904 - mse: 0.1904 - val_loss: 0.1831 - val_mse: 0.1831
Epoch 4/100
1068/1068 - 1s - loss: 0.1837 - mse: 0.1837 - val_loss: 0.1764 - val_mse: 0.1764
Epoch 5/100
1068/1068 - 1s - loss: 0.1702 - mse: 0.1702 - val_loss: 0.1599 - val_mse: 0.1599
Epoch 6/100
1068/1068 - 1s - loss: 0.1554 - mse: 0.1554 - val_loss: 0.1514 - val_mse: 0.1514
Epoch 7/100
1068/1068 - 1s - loss: 0.1459 - mse: 0.1459 - val_loss: 0.1396 - val_mse: 0.1396
Epoch 8/100
1068/1068 - 1s - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1304 - val_mse: 0.1304
Epoch 9/100
1068/1068 - 1s - loss: 0.1287 - mse: 0.1287 - val_loss: 0.1233 - val_mse: 0.1233
Epoch 10/100
1068/1068 - 1s - loss: 0.1212 - mse: 0.1212 - val_loss: 0.1165 - val_mse: 0.1165
Epoch 11/100
1068/1068 - 1s - loss: 0.1153 - mse: 0.1153 - val_loss: 0.1104 - val_mse: 0.1104
Epoch 12/100
1068/1068 - 1s - loss: 0.1084 - mse: 0.1084 - val_loss: 0.1043 - val_mse: 0.1043
Epoch 13/100
1068/1068 - 1s - loss: 0.1018 - mse: 0.1018 - val_loss: 0.0995 - val_mse: 0.0995
Epoch 14/100
1068/1068 - 1s - loss: 0.0963 - mse: 0.0963 - val_loss: 0.0930 - val_mse: 0.0930
Epoch 15/100
1068/1068 - 1s - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0883 - val_mse: 0.0883
Epoch 16/100
1068/1068 - 1s - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0836 - val_mse: 0.0836
Epoch 17/100
1068/1068 - 1s - loss: 0.0805 - mse: 0.0805 - val_loss: 0.0810 - val_mse: 0.0810
Epoch 18/100
1068/1068 - 1s - loss: 0.0764 - mse: 0.0764 - val_loss: 0.0749 - val_mse: 0.0749
Epoch 19/100
1068/1068 - 1s - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0684 - val_mse: 0.0684
Epoch 20/100
1068/1068 - 1s - loss: 0.0667 - mse: 0.0667 - val_loss: 0.0650 - val_mse: 0.0650
Epoch 21/100
1068/1068 - 1s - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0584 - val_mse: 0.0584
Epoch 22/100
1068/1068 - 1s - loss: 0.0575 - mse: 0.0575 - val_loss: 0.0501 - val_mse: 0.0501
Epoch 23/100
1068/1068 - 1s - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0456 - val_mse: 0.0456
Epoch 24/100
1068/1068 - 1s - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0411 - val_mse: 0.0411
Epoch 25/100
1068/1068 - 1s - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0381 - val_mse: 0.0381
Epoch 26/100
1068/1068 - 1s - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0381 - val_mse: 0.0381
Epoch 27/100
1068/1068 - 1s - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0349 - val_mse: 0.0349
Epoch 28/100
1068/1068 - 1s - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0329 - val_mse: 0.0329
Epoch 29/100
1068/1068 - 1s - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0309 - val_mse: 0.0309
Epoch 30/100
1068/1068 - 1s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 31/100
1068/1068 - 1s - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 32/100
1068/1068 - 1s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 33/100
1068/1068 - 1s - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 34/100
1068/1068 - 1s - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 35/100
1068/1068 - 1s - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0269 - val_mse: 0.0269
Epoch 36/100
1068/1068 - 1s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0229 - val_mse: 0.0229
Epoch 37/100
1068/1068 - 1s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0237 - val_mse: 0.0237
Epoch 38/100
1068/1068 - 1s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0243 - val_mse: 0.0243
Epoch 39/100
1068/1068 - 1s - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0240 - val_mse: 0.0240
Epoch 40/100
1068/1068 - 1s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0212 - val_mse: 0.0212
Epoch 41/100
1068/1068 - 1s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0209 - val_mse: 0.0209
Epoch 42/100
1068/1068 - 1s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0203 - val_mse: 0.0203
Epoch 43/100
1068/1068 - 1s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0205 - val_mse: 0.0205
Epoch 44/100
1068/1068 - 1s - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0204 - val_mse: 0.0204
Epoch 45/100
1068/1068 - 1s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0216 - val_mse: 0.0216
Epoch 46/100
1068/1068 - 1s - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0224 - val_mse: 0.0224
Epoch 47/100
1068/1068 - 1s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0203 - val_mse: 0.0203
Epoch 48/100
1068/1068 - 1s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0198 - val_mse: 0.0198
Epoch 49/100
1068/1068 - 1s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0209 - val_mse: 0.0209
Epoch 50/100
1068/1068 - 1s - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0201 - val_mse: 0.0201
Epoch 51/100
1068/1068 - 1s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0199 - val_mse: 0.0199
Epoch 52/100
1068/1068 - 1s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0188 - val_mse: 0.0188
Epoch 53/100
1068/1068 - 1s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 54/100
1068/1068 - 1s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0191 - val_mse: 0.0191
Epoch 55/100
1068/1068 - 1s - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 56/100
1068/1068 - 1s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 57/100
1068/1068 - 1s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0182 - val_mse: 0.0182
Epoch 58/100
1068/1068 - 1s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 59/100
1068/1068 - 1s - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 60/100
1068/1068 - 1s - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 61/100
1068/1068 - 1s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0192 - val_mse: 0.0192
Epoch 62/100
1068/1068 - 1s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 63/100
1068/1068 - 1s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0179 - val_mse: 0.0179
Epoch 64/100
1068/1068 - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0178 - val_mse: 0.0178
Epoch 65/100
1068/1068 - 1s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0180 - val_mse: 0.0180
Epoch 66/100
1068/1068 - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 67/100
1068/1068 - 1s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0174 - val_mse: 0.0174
Epoch 68/100
1068/1068 - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0179 - val_mse: 0.0179
Epoch 69/100
1068/1068 - 1s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0186 - val_mse: 0.0186
Epoch 70/100
1068/1068 - 1s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0192 - val_mse: 0.0192
Epoch 71/100
1068/1068 - 1s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0178 - val_mse: 0.0178
Epoch 72/100
1068/1068 - 1s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 73/100
1068/1068 - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 74/100
1068/1068 - 1s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0205 - val_mse: 0.0205
Epoch 75/100
1068/1068 - 1s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0185 - val_mse: 0.0185
Epoch 76/100
1068/1068 - 1s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 77/100
1068/1068 - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0178 - val_mse: 0.0178
saving model CNNxySTOCHASTIC0
model 1/120
time elapsed:
00:00:57.78
estimated time left:
01:54:36.28 


STOCHASTIC run: 1
Train on 988 samples, validate on 247 samples
Epoch 1/100
988/988 - 2s - loss: 0.2743 - mse: 0.2743 - val_loss: 0.2099 - val_mse: 0.2099
Epoch 2/100
988/988 - 1s - loss: 0.1761 - mse: 0.1761 - val_loss: 0.1425 - val_mse: 0.1425
Epoch 3/100
988/988 - 1s - loss: 0.1297 - mse: 0.1297 - val_loss: 0.1049 - val_mse: 0.1049
Epoch 4/100
988/988 - 1s - loss: 0.0926 - mse: 0.0926 - val_loss: 0.0655 - val_mse: 0.0655
Epoch 5/100
988/988 - 1s - loss: 0.0601 - mse: 0.0601 - val_loss: 0.0532 - val_mse: 0.0532
Epoch 6/100
988/988 - 1s - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0457 - val_mse: 0.0457
Epoch 7/100
988/988 - 1s - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0438 - val_mse: 0.0438
Epoch 8/100
988/988 - 1s - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0389 - val_mse: 0.0389
Epoch 9/100
988/988 - 1s - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0362 - val_mse: 0.0362
Epoch 10/100
988/988 - 1s - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0301 - val_mse: 0.0301
Epoch 11/100
988/988 - 1s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 12/100
988/988 - 1s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 13/100
988/988 - 1s - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 14/100
988/988 - 1s - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0196 - val_mse: 0.0196
Epoch 15/100
988/988 - 1s - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0191 - val_mse: 0.0191
Epoch 16/100
988/988 - 1s - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0182 - val_mse: 0.0182
Epoch 17/100
988/988 - 1s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0155 - val_mse: 0.0155
Epoch 18/100
988/988 - 1s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 19/100
988/988 - 1s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 20/100
988/988 - 1s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0130 - val_mse: 0.0130
Epoch 21/100
988/988 - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 22/100
988/988 - 1s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0123 - val_mse: 0.0123
Epoch 23/100
988/988 - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 24/100
988/988 - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 25/100
988/988 - 1s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0118 - val_mse: 0.0118
Epoch 26/100
988/988 - 1s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 27/100
988/988 - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0112 - val_mse: 0.0112
Epoch 28/100
988/988 - 1s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 29/100
988/988 - 1s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0114 - val_mse: 0.0114
Epoch 30/100
988/988 - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0107 - val_mse: 0.0107
Epoch 31/100
988/988 - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0111 - val_mse: 0.0111
Epoch 32/100
988/988 - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0108 - val_mse: 0.0108
Epoch 33/100
988/988 - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0109 - val_mse: 0.0109
Epoch 34/100
988/988 - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0108 - val_mse: 0.0108
Epoch 35/100
988/988 - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0110 - val_mse: 0.0110
Epoch 36/100
988/988 - 1s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0108 - val_mse: 0.0108
Epoch 37/100
988/988 - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0111 - val_mse: 0.0111
Epoch 38/100
988/988 - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0110 - val_mse: 0.0110
Epoch 39/100
988/988 - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0109 - val_mse: 0.0109
Epoch 40/100
988/988 - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0114 - val_mse: 0.0114
saving model CNNxySTOCHASTIC1
model 2/120
time elapsed:
00:01:23.73
estimated time left:
01:22:19.88 


STOCHASTIC run: 2
Train on 908 samples, validate on 227 samples
Epoch 1/100
908/908 - 2s - loss: 0.2094 - mse: 0.2094 - val_loss: 0.1775 - val_mse: 0.1775
Epoch 2/100
908/908 - 1s - loss: 0.1665 - mse: 0.1665 - val_loss: 0.1350 - val_mse: 0.1350
Epoch 3/100
908/908 - 1s - loss: 0.1161 - mse: 0.1161 - val_loss: 0.1070 - val_mse: 0.1070
Epoch 4/100
908/908 - 1s - loss: 0.0995 - mse: 0.0995 - val_loss: 0.0969 - val_mse: 0.0969
Epoch 5/100
908/908 - 1s - loss: 0.0775 - mse: 0.0775 - val_loss: 0.0638 - val_mse: 0.0638
Epoch 6/100
908/908 - 1s - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0820 - val_mse: 0.0820
Epoch 7/100
908/908 - 1s - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0708 - val_mse: 0.0708
Epoch 8/100
908/908 - 1s - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0512 - val_mse: 0.0512
Epoch 9/100
908/908 - 1s - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0469 - val_mse: 0.0469
Epoch 10/100
908/908 - 1s - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0465 - val_mse: 0.0465
Epoch 11/100
908/908 - 1s - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0452 - val_mse: 0.0452
Epoch 12/100
908/908 - 1s - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0428 - val_mse: 0.0428
Epoch 13/100
908/908 - 1s - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0396 - val_mse: 0.0396
Epoch 14/100
908/908 - 1s - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0385 - val_mse: 0.0385
Epoch 15/100
908/908 - 1s - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0377 - val_mse: 0.0377
Epoch 16/100
908/908 - 1s - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0375 - val_mse: 0.0375
Epoch 17/100
908/908 - 1s - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 18/100
908/908 - 1s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 19/100
908/908 - 1s - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 20/100
908/908 - 1s - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0259 - val_mse: 0.0259
Epoch 21/100
908/908 - 1s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0233 - val_mse: 0.0233
Epoch 22/100
908/908 - 1s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 23/100
908/908 - 1s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 24/100
908/908 - 1s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 25/100
908/908 - 1s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0189 - val_mse: 0.0189
Epoch 26/100
908/908 - 1s - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0180 - val_mse: 0.0180
Epoch 27/100
908/908 - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0163 - val_mse: 0.0163
Epoch 28/100
908/908 - 1s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0154 - val_mse: 0.0154
Epoch 29/100
908/908 - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 30/100
908/908 - 1s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 31/100
908/908 - 1s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0156 - val_mse: 0.0156
Epoch 32/100
908/908 - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 33/100
908/908 - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 34/100
908/908 - 1s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0167 - val_mse: 0.0167
Epoch 35/100
908/908 - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 36/100
908/908 - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 37/100
908/908 - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0126 - val_mse: 0.0126
Epoch 38/100
908/908 - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0129 - val_mse: 0.0129
Epoch 39/100
908/908 - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 40/100
908/908 - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0123 - val_mse: 0.0123
Epoch 41/100
908/908 - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0129 - val_mse: 0.0129
Epoch 42/100
908/908 - 1s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0116 - val_mse: 0.0116
Epoch 43/100
908/908 - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0120 - val_mse: 0.0120
Epoch 44/100
908/908 - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0128 - val_mse: 0.0128
Epoch 45/100
908/908 - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 46/100
908/908 - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0115 - val_mse: 0.0115
Epoch 47/100
908/908 - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0118 - val_mse: 0.0118
Epoch 48/100
908/908 - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0125 - val_mse: 0.0125
Epoch 49/100
908/908 - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 50/100
908/908 - 1s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 51/100
908/908 - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 52/100
908/908 - 1s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 53/100
908/908 - 1s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0125 - val_mse: 0.0125
Epoch 54/100
908/908 - 1s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0122 - val_mse: 0.0122
Epoch 55/100
908/908 - 1s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0116 - val_mse: 0.0116
Epoch 56/100
908/908 - 1s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0121 - val_mse: 0.0121
saving model CNNxySTOCHASTIC2
model 3/120
time elapsed:
00:01:56.79
estimated time left:
01:15:54.75 


STOCHASTIC run: 3
Train on 828 samples, validate on 207 samples
Epoch 1/100
828/828 - 2s - loss: 0.6139 - mse: 0.6139 - val_loss: 0.2312 - val_mse: 0.2312
Epoch 2/100
828/828 - 1s - loss: 0.1991 - mse: 0.1991 - val_loss: 0.1919 - val_mse: 0.1919
Epoch 3/100
828/828 - 1s - loss: 0.1933 - mse: 0.1933 - val_loss: 0.1919 - val_mse: 0.1919
Epoch 4/100
828/828 - 0s - loss: 0.1910 - mse: 0.1910 - val_loss: 0.1916 - val_mse: 0.1916
Epoch 5/100
828/828 - 1s - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876
Epoch 6/100
828/828 - 0s - loss: 0.1822 - mse: 0.1822 - val_loss: 0.1811 - val_mse: 0.1811
Epoch 7/100
828/828 - 0s - loss: 0.1721 - mse: 0.1721 - val_loss: 0.1692 - val_mse: 0.1692
Epoch 8/100
828/828 - 1s - loss: 0.1615 - mse: 0.1615 - val_loss: 0.1616 - val_mse: 0.1616
Epoch 9/100
828/828 - 0s - loss: 0.1546 - mse: 0.1546 - val_loss: 0.1542 - val_mse: 0.1542
Epoch 10/100
828/828 - 0s - loss: 0.1481 - mse: 0.1481 - val_loss: 0.1491 - val_mse: 0.1491
Epoch 11/100
828/828 - 0s - loss: 0.1430 - mse: 0.1430 - val_loss: 0.1465 - val_mse: 0.1465
Epoch 12/100
828/828 - 1s - loss: 0.1403 - mse: 0.1403 - val_loss: 0.1422 - val_mse: 0.1422
Epoch 13/100
828/828 - 1s - loss: 0.1364 - mse: 0.1364 - val_loss: 0.1371 - val_mse: 0.1371
Epoch 14/100
828/828 - 0s - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1327 - val_mse: 0.1327
Epoch 15/100
828/828 - 1s - loss: 0.1283 - mse: 0.1283 - val_loss: 0.1301 - val_mse: 0.1301
Epoch 16/100
828/828 - 1s - loss: 0.1249 - mse: 0.1249 - val_loss: 0.1276 - val_mse: 0.1276
Epoch 17/100
828/828 - 1s - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1239 - val_mse: 0.1239
Epoch 18/100
828/828 - 0s - loss: 0.1210 - mse: 0.1210 - val_loss: 0.1257 - val_mse: 0.1257
Epoch 19/100
828/828 - 0s - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1195 - val_mse: 0.1195
Epoch 20/100
828/828 - 1s - loss: 0.1134 - mse: 0.1134 - val_loss: 0.1173 - val_mse: 0.1173
Epoch 21/100
828/828 - 1s - loss: 0.1099 - mse: 0.1099 - val_loss: 0.1145 - val_mse: 0.1145
Epoch 22/100
828/828 - 1s - loss: 0.1075 - mse: 0.1075 - val_loss: 0.1103 - val_mse: 0.1103
Epoch 23/100
828/828 - 1s - loss: 0.1039 - mse: 0.1039 - val_loss: 0.1095 - val_mse: 0.1095
Epoch 24/100
828/828 - 1s - loss: 0.1020 - mse: 0.1020 - val_loss: 0.1070 - val_mse: 0.1070
Epoch 25/100
828/828 - 1s - loss: 0.1004 - mse: 0.1004 - val_loss: 0.1040 - val_mse: 0.1040
Epoch 26/100
828/828 - 0s - loss: 0.0973 - mse: 0.0973 - val_loss: 0.1017 - val_mse: 0.1017
Epoch 27/100
828/828 - 1s - loss: 0.0948 - mse: 0.0948 - val_loss: 0.1017 - val_mse: 0.1017
Epoch 28/100
828/828 - 1s - loss: 0.0926 - mse: 0.0926 - val_loss: 0.0960 - val_mse: 0.0960
Epoch 29/100
828/828 - 0s - loss: 0.0902 - mse: 0.0902 - val_loss: 0.0969 - val_mse: 0.0969
Epoch 30/100
828/828 - 0s - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0938 - val_mse: 0.0938
Epoch 31/100
828/828 - 1s - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0936 - val_mse: 0.0936
Epoch 32/100
828/828 - 1s - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0896 - val_mse: 0.0896
Epoch 33/100
828/828 - 0s - loss: 0.0842 - mse: 0.0842 - val_loss: 0.0884 - val_mse: 0.0884
Epoch 34/100
828/828 - 1s - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0860 - val_mse: 0.0860
Epoch 35/100
828/828 - 0s - loss: 0.0821 - mse: 0.0821 - val_loss: 0.0881 - val_mse: 0.0881
Epoch 36/100
828/828 - 1s - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0799 - val_mse: 0.0799
Epoch 37/100
828/828 - 1s - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0798 - val_mse: 0.0798
Epoch 38/100
828/828 - 1s - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0761 - val_mse: 0.0761
Epoch 39/100
828/828 - 1s - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0738 - val_mse: 0.0738
Epoch 40/100
828/828 - 1s - loss: 0.0682 - mse: 0.0682 - val_loss: 0.0710 - val_mse: 0.0710
Epoch 41/100
828/828 - 0s - loss: 0.0674 - mse: 0.0674 - val_loss: 0.0734 - val_mse: 0.0734
Epoch 42/100
828/828 - 1s - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0689 - val_mse: 0.0689
Epoch 43/100
828/828 - 1s - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0669 - val_mse: 0.0669
Epoch 44/100
828/828 - 1s - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0631 - val_mse: 0.0631
Epoch 45/100
828/828 - 1s - loss: 0.0577 - mse: 0.0577 - val_loss: 0.0630 - val_mse: 0.0630
Epoch 46/100
828/828 - 0s - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0617 - val_mse: 0.0617
Epoch 47/100
828/828 - 1s - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0607 - val_mse: 0.0607
Epoch 48/100
828/828 - 1s - loss: 0.0521 - mse: 0.0521 - val_loss: 0.0583 - val_mse: 0.0583
Epoch 49/100
828/828 - 1s - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0554 - val_mse: 0.0554
Epoch 50/100
828/828 - 1s - loss: 0.0485 - mse: 0.0485 - val_loss: 0.0548 - val_mse: 0.0548
Epoch 51/100
828/828 - 1s - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0530 - val_mse: 0.0530
Epoch 52/100
828/828 - 0s - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0548 - val_mse: 0.0548
Epoch 53/100
828/828 - 1s - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0579 - val_mse: 0.0579
Epoch 54/100
828/828 - 1s - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0526 - val_mse: 0.0526
Epoch 55/100
828/828 - 1s - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0504 - val_mse: 0.0504
Epoch 56/100
828/828 - 1s - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0477 - val_mse: 0.0477
Epoch 57/100
828/828 - 1s - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0464 - val_mse: 0.0464
Epoch 58/100
828/828 - 1s - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0449 - val_mse: 0.0449
Epoch 59/100
828/828 - 1s - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0462 - val_mse: 0.0462
Epoch 60/100
828/828 - 0s - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0463 - val_mse: 0.0463
Epoch 61/100
828/828 - 0s - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0445 - val_mse: 0.0445
Epoch 62/100
828/828 - 0s - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0441 - val_mse: 0.0441
Epoch 63/100
828/828 - 0s - loss: 0.0280 - mse: 0.0280 - val_loss: 0.0427 - val_mse: 0.0427
Epoch 64/100
828/828 - 1s - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0391 - val_mse: 0.0391
Epoch 65/100
828/828 - 1s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0413 - val_mse: 0.0413
Epoch 66/100
828/828 - 0s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0426 - val_mse: 0.0426
Epoch 67/100
828/828 - 1s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0411 - val_mse: 0.0411
Epoch 68/100
828/828 - 1s - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0370 - val_mse: 0.0370
Epoch 69/100
828/828 - 0s - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0364 - val_mse: 0.0364
Epoch 70/100
828/828 - 0s - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0362 - val_mse: 0.0362
Epoch 71/100
828/828 - 0s - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0366 - val_mse: 0.0366
Epoch 72/100
828/828 - 1s - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0359 - val_mse: 0.0359
Epoch 73/100
828/828 - 1s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0361 - val_mse: 0.0361
Epoch 74/100
828/828 - 1s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0404 - val_mse: 0.0404
Epoch 75/100
828/828 - 1s - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0373 - val_mse: 0.0373
Epoch 76/100
828/828 - 0s - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0362 - val_mse: 0.0362
Epoch 77/100
828/828 - 1s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0363 - val_mse: 0.0363
Epoch 78/100
828/828 - 1s - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0359 - val_mse: 0.0359
Epoch 79/100
828/828 - 0s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0362 - val_mse: 0.0362
Epoch 80/100
828/828 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0363 - val_mse: 0.0363
Epoch 81/100
828/828 - 1s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0354 - val_mse: 0.0354
Epoch 82/100
828/828 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0355 - val_mse: 0.0355
Epoch 83/100
828/828 - 1s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0354 - val_mse: 0.0354
Epoch 84/100
828/828 - 1s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0355 - val_mse: 0.0355
Epoch 85/100
828/828 - 1s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 86/100
828/828 - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0359 - val_mse: 0.0359
Epoch 87/100
828/828 - 1s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0353 - val_mse: 0.0353
Epoch 88/100
828/828 - 1s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0348 - val_mse: 0.0348
Epoch 89/100
828/828 - 1s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0363 - val_mse: 0.0363
Epoch 90/100
828/828 - 1s - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0350 - val_mse: 0.0350
Epoch 91/100
828/828 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 92/100
828/828 - 1s - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0342 - val_mse: 0.0342
Epoch 93/100
828/828 - 1s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 94/100
828/828 - 1s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0347 - val_mse: 0.0347
Epoch 95/100
828/828 - 0s - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0362 - val_mse: 0.0362
Epoch 96/100
828/828 - 0s - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0358 - val_mse: 0.0358
Epoch 97/100
828/828 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 98/100
828/828 - 0s - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0339 - val_mse: 0.0339
Epoch 99/100
828/828 - 0s - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0349 - val_mse: 0.0349
Epoch 100/100
828/828 - 0s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0348 - val_mse: 0.0348
saving model CNNxySTOCHASTIC3
model 4/120
time elapsed:
00:02:49.20
estimated time left:
01:21:46.72 


STOCHASTIC run: 4
Train on 748 samples, validate on 187 samples
Epoch 1/100
748/748 - 2s - loss: 0.5480 - mse: 0.5480 - val_loss: 0.2106 - val_mse: 0.2106
Epoch 2/100
748/748 - 0s - loss: 0.1922 - mse: 0.1922 - val_loss: 0.1929 - val_mse: 0.1929
Epoch 3/100
748/748 - 0s - loss: 0.1911 - mse: 0.1911 - val_loss: 0.1912 - val_mse: 0.1912
Epoch 4/100
748/748 - 0s - loss: 0.1829 - mse: 0.1829 - val_loss: 0.1783 - val_mse: 0.1783
Epoch 5/100
748/748 - 0s - loss: 0.1708 - mse: 0.1708 - val_loss: 0.1650 - val_mse: 0.1650
Epoch 6/100
748/748 - 0s - loss: 0.1560 - mse: 0.1560 - val_loss: 0.1534 - val_mse: 0.1534
Epoch 7/100
748/748 - 0s - loss: 0.1429 - mse: 0.1429 - val_loss: 0.1418 - val_mse: 0.1418
Epoch 8/100
748/748 - 0s - loss: 0.1289 - mse: 0.1289 - val_loss: 0.1260 - val_mse: 0.1260
Epoch 9/100
748/748 - 0s - loss: 0.1188 - mse: 0.1188 - val_loss: 0.1202 - val_mse: 0.1202
Epoch 10/100
748/748 - 0s - loss: 0.1115 - mse: 0.1115 - val_loss: 0.1112 - val_mse: 0.1112
Epoch 11/100
748/748 - 0s - loss: 0.1041 - mse: 0.1041 - val_loss: 0.1046 - val_mse: 0.1046
Epoch 12/100
748/748 - 0s - loss: 0.0987 - mse: 0.0987 - val_loss: 0.0968 - val_mse: 0.0968
Epoch 13/100
748/748 - 0s - loss: 0.0918 - mse: 0.0918 - val_loss: 0.0908 - val_mse: 0.0908
Epoch 14/100
748/748 - 0s - loss: 0.0847 - mse: 0.0847 - val_loss: 0.0853 - val_mse: 0.0853
Epoch 15/100
748/748 - 0s - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0798 - val_mse: 0.0798
Epoch 16/100
748/748 - 0s - loss: 0.0730 - mse: 0.0730 - val_loss: 0.0719 - val_mse: 0.0719
Epoch 17/100
748/748 - 0s - loss: 0.0681 - mse: 0.0681 - val_loss: 0.0677 - val_mse: 0.0677
Epoch 18/100
748/748 - 0s - loss: 0.0620 - mse: 0.0620 - val_loss: 0.0623 - val_mse: 0.0623
Epoch 19/100
748/748 - 0s - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0562 - val_mse: 0.0562
Epoch 20/100
748/748 - 0s - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0513 - val_mse: 0.0513
Epoch 21/100
748/748 - 0s - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0478 - val_mse: 0.0478
Epoch 22/100
748/748 - 0s - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0451 - val_mse: 0.0451
Epoch 23/100
748/748 - 0s - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0448 - val_mse: 0.0448
Epoch 24/100
748/748 - 0s - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0438 - val_mse: 0.0438
Epoch 25/100
748/748 - 0s - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0385 - val_mse: 0.0385
Epoch 26/100
748/748 - 0s - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0361 - val_mse: 0.0361
Epoch 27/100
748/748 - 0s - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0345 - val_mse: 0.0345
Epoch 28/100
748/748 - 0s - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0342 - val_mse: 0.0342
Epoch 29/100
748/748 - 0s - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0335 - val_mse: 0.0335
Epoch 30/100
748/748 - 0s - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0324 - val_mse: 0.0324
Epoch 31/100
748/748 - 0s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0310 - val_mse: 0.0310
Epoch 32/100
748/748 - 0s - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0324 - val_mse: 0.0324
Epoch 33/100
748/748 - 0s - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0310 - val_mse: 0.0310
Epoch 34/100
748/748 - 0s - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0305 - val_mse: 0.0305
Epoch 35/100
748/748 - 0s - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0345 - val_mse: 0.0345
Epoch 36/100
748/748 - 0s - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0318 - val_mse: 0.0318
Epoch 37/100
748/748 - 0s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 38/100
748/748 - 0s - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0287 - val_mse: 0.0287
Epoch 39/100
748/748 - 0s - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0260 - val_mse: 0.0260
Epoch 40/100
748/748 - 0s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0274 - val_mse: 0.0274
Epoch 41/100
748/748 - 0s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0273 - val_mse: 0.0273
Epoch 42/100
748/748 - 0s - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0273 - val_mse: 0.0273
Epoch 43/100
748/748 - 0s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0256 - val_mse: 0.0256
Epoch 44/100
748/748 - 0s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0252 - val_mse: 0.0252
Epoch 45/100
748/748 - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0275 - val_mse: 0.0275
Epoch 46/100
748/748 - 0s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0279 - val_mse: 0.0279
Epoch 47/100
748/748 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 48/100
748/748 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0237 - val_mse: 0.0237
Epoch 49/100
748/748 - 0s - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0269 - val_mse: 0.0269
Epoch 50/100
748/748 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 51/100
748/748 - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0241 - val_mse: 0.0241
Epoch 52/100
748/748 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0244 - val_mse: 0.0244
Epoch 53/100
748/748 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0235 - val_mse: 0.0235
Epoch 54/100
748/748 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0238 - val_mse: 0.0238
Epoch 55/100
748/748 - 0s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 56/100
748/748 - 0s - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 57/100
748/748 - 0s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 58/100
748/748 - 0s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0256 - val_mse: 0.0256
Epoch 59/100
748/748 - 0s - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0258 - val_mse: 0.0258
Epoch 60/100
748/748 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0256 - val_mse: 0.0256
Epoch 61/100
748/748 - 0s - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0232 - val_mse: 0.0232
Epoch 62/100
748/748 - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0232 - val_mse: 0.0232
Epoch 63/100
748/748 - 0s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 64/100
748/748 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0235 - val_mse: 0.0235
Epoch 65/100
748/748 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0227 - val_mse: 0.0227
Epoch 66/100
748/748 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0238 - val_mse: 0.0238
Epoch 67/100
748/748 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0234 - val_mse: 0.0234
Epoch 68/100
748/748 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 69/100
748/748 - 0s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 70/100
748/748 - 0s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0239 - val_mse: 0.0239
Epoch 71/100
748/748 - 0s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0240 - val_mse: 0.0240
Epoch 72/100
748/748 - 0s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0241 - val_mse: 0.0241
Epoch 73/100
748/748 - 0s - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0243 - val_mse: 0.0243
Epoch 74/100
748/748 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0232 - val_mse: 0.0232
Epoch 75/100
748/748 - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0233 - val_mse: 0.0233
saving model CNNxySTOCHASTIC4
model 5/120
time elapsed:
00:03:25.16
estimated time left:
01:18:38.60 


STOCHASTIC run: 5
Train on 668 samples, validate on 167 samples
Epoch 1/100
668/668 - 1s - loss: 0.2865 - mse: 0.2865 - val_loss: 0.1859 - val_mse: 0.1859
Epoch 2/100
668/668 - 0s - loss: 0.1824 - mse: 0.1824 - val_loss: 0.1517 - val_mse: 0.1517
Epoch 3/100
668/668 - 0s - loss: 0.1363 - mse: 0.1363 - val_loss: 0.1172 - val_mse: 0.1172
Epoch 4/100
668/668 - 0s - loss: 0.1211 - mse: 0.1211 - val_loss: 0.0997 - val_mse: 0.0997
Epoch 5/100
668/668 - 0s - loss: 0.1022 - mse: 0.1022 - val_loss: 0.0839 - val_mse: 0.0839
Epoch 6/100
668/668 - 0s - loss: 0.0776 - mse: 0.0776 - val_loss: 0.0607 - val_mse: 0.0607
Epoch 7/100
668/668 - 0s - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0610 - val_mse: 0.0610
Epoch 8/100
668/668 - 0s - loss: 0.0549 - mse: 0.0549 - val_loss: 0.0488 - val_mse: 0.0488
Epoch 9/100
668/668 - 0s - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0402 - val_mse: 0.0402
Epoch 10/100
668/668 - 0s - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0366 - val_mse: 0.0366
Epoch 11/100
668/668 - 0s - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0335 - val_mse: 0.0335
Epoch 12/100
668/668 - 0s - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 13/100
668/668 - 0s - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0284 - val_mse: 0.0284
Epoch 14/100
668/668 - 0s - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 15/100
668/668 - 0s - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 16/100
668/668 - 0s - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0254 - val_mse: 0.0254
Epoch 17/100
668/668 - 0s - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0239 - val_mse: 0.0239
Epoch 18/100
668/668 - 0s - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0225 - val_mse: 0.0225
Epoch 19/100
668/668 - 0s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0202 - val_mse: 0.0202
Epoch 20/100
668/668 - 0s - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0202 - val_mse: 0.0202
Epoch 21/100
668/668 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0172 - val_mse: 0.0172
Epoch 22/100
668/668 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0165 - val_mse: 0.0165
Epoch 23/100
668/668 - 0s - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0166 - val_mse: 0.0166
Epoch 24/100
668/668 - 0s - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0150 - val_mse: 0.0150
Epoch 25/100
668/668 - 0s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 26/100
668/668 - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 27/100
668/668 - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0130 - val_mse: 0.0130
Epoch 28/100
668/668 - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 29/100
668/668 - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 30/100
668/668 - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 31/100
668/668 - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0121 - val_mse: 0.0121
Epoch 32/100
668/668 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0118 - val_mse: 0.0118
Epoch 33/100
668/668 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 34/100
668/668 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0115 - val_mse: 0.0115
Epoch 35/100
668/668 - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 36/100
668/668 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0118 - val_mse: 0.0118
Epoch 37/100
668/668 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0116 - val_mse: 0.0116
Epoch 38/100
668/668 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 39/100
668/668 - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0115 - val_mse: 0.0115
Epoch 40/100
668/668 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0113 - val_mse: 0.0113
Epoch 41/100
668/668 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0115 - val_mse: 0.0115
Epoch 42/100
668/668 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 43/100
668/668 - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0116 - val_mse: 0.0116
Epoch 44/100
668/668 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0114 - val_mse: 0.0114
Epoch 45/100
668/668 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0118 - val_mse: 0.0118
Epoch 46/100
668/668 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0121 - val_mse: 0.0121
Epoch 47/100
668/668 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0114 - val_mse: 0.0114
Epoch 48/100
668/668 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0119 - val_mse: 0.0119
Epoch 49/100
668/668 - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0117 - val_mse: 0.0117
Epoch 50/100
668/668 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0114 - val_mse: 0.0114
saving model CNNxySTOCHASTIC5
model 6/120
time elapsed:
00:03:47.31
estimated time left:
01:11:58.80 


STOCHASTIC run: 6
Train on 588 samples, validate on 147 samples
Epoch 1/100
588/588 - 2s - loss: 0.2631 - mse: 0.2631 - val_loss: 0.2111 - val_mse: 0.2111
Epoch 2/100
588/588 - 0s - loss: 0.2000 - mse: 0.2000 - val_loss: 0.1909 - val_mse: 0.1909
Epoch 3/100
588/588 - 0s - loss: 0.1800 - mse: 0.1800 - val_loss: 0.1672 - val_mse: 0.1672
Epoch 4/100
588/588 - 0s - loss: 0.1480 - mse: 0.1480 - val_loss: 0.1173 - val_mse: 0.1173
Epoch 5/100
588/588 - 0s - loss: 0.1115 - mse: 0.1115 - val_loss: 0.0919 - val_mse: 0.0919
Epoch 6/100
588/588 - 0s - loss: 0.0845 - mse: 0.0845 - val_loss: 0.0655 - val_mse: 0.0655
Epoch 7/100
588/588 - 0s - loss: 0.0660 - mse: 0.0660 - val_loss: 0.0604 - val_mse: 0.0604
Epoch 8/100
588/588 - 0s - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0539 - val_mse: 0.0539
Epoch 9/100
588/588 - 0s - loss: 0.0502 - mse: 0.0502 - val_loss: 0.0504 - val_mse: 0.0504
Epoch 10/100
588/588 - 0s - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0469 - val_mse: 0.0469
Epoch 11/100
588/588 - 0s - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0453 - val_mse: 0.0453
Epoch 12/100
588/588 - 0s - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0457 - val_mse: 0.0457
Epoch 13/100
588/588 - 0s - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0435 - val_mse: 0.0435
Epoch 14/100
588/588 - 0s - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0413 - val_mse: 0.0413
Epoch 15/100
588/588 - 0s - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0403 - val_mse: 0.0403
Epoch 16/100
588/588 - 0s - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0376 - val_mse: 0.0376
Epoch 17/100
588/588 - 0s - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0377 - val_mse: 0.0377
Epoch 18/100
588/588 - 0s - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 19/100
588/588 - 0s - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0327 - val_mse: 0.0327
Epoch 20/100
588/588 - 0s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0306 - val_mse: 0.0306
Epoch 21/100
588/588 - 0s - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0336 - val_mse: 0.0336
Epoch 22/100
588/588 - 0s - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0312 - val_mse: 0.0312
Epoch 23/100
588/588 - 0s - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0280 - val_mse: 0.0280
Epoch 24/100
588/588 - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0257 - val_mse: 0.0257
Epoch 25/100
588/588 - 0s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0246 - val_mse: 0.0246
Epoch 26/100
588/588 - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0245 - val_mse: 0.0245
Epoch 27/100
588/588 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0234 - val_mse: 0.0234
Epoch 28/100
588/588 - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0232 - val_mse: 0.0232
Epoch 29/100
588/588 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 30/100
588/588 - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 31/100
588/588 - 0s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0216 - val_mse: 0.0216
Epoch 32/100
588/588 - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0225 - val_mse: 0.0225
Epoch 33/100
588/588 - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0206 - val_mse: 0.0206
Epoch 34/100
588/588 - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0192 - val_mse: 0.0192
Epoch 35/100
588/588 - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 36/100
588/588 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 37/100
588/588 - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 38/100
588/588 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0195 - val_mse: 0.0195
Epoch 39/100
588/588 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 40/100
588/588 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0189 - val_mse: 0.0189
Epoch 41/100
588/588 - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0194 - val_mse: 0.0194
Epoch 42/100
588/588 - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 43/100
588/588 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 44/100
588/588 - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 45/100
588/588 - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 46/100
588/588 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0179 - val_mse: 0.0179
Epoch 47/100
588/588 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0175 - val_mse: 0.0175
Epoch 48/100
588/588 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0174 - val_mse: 0.0174
Epoch 49/100
588/588 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0174 - val_mse: 0.0174
Epoch 50/100
588/588 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 51/100
588/588 - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0191 - val_mse: 0.0191
Epoch 52/100
588/588 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 53/100
588/588 - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0182 - val_mse: 0.0182
Epoch 54/100
588/588 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 55/100
588/588 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0178 - val_mse: 0.0178
Epoch 56/100
588/588 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0182 - val_mse: 0.0182
Epoch 57/100
588/588 - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0189 - val_mse: 0.0189
Epoch 58/100
588/588 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 59/100
588/588 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0177 - val_mse: 0.0177
saving model CNNxySTOCHASTIC6
model 7/120
time elapsed:
00:04:10.55
estimated time left:
01:07:24.57 


STOCHASTIC run: 7
Train on 508 samples, validate on 127 samples
Epoch 1/100
508/508 - 1s - loss: 0.2293 - mse: 0.2293 - val_loss: 0.1847 - val_mse: 0.1847
Epoch 2/100
508/508 - 0s - loss: 0.1850 - mse: 0.1850 - val_loss: 0.1745 - val_mse: 0.1745
Epoch 3/100
508/508 - 0s - loss: 0.1683 - mse: 0.1683 - val_loss: 0.1567 - val_mse: 0.1567
Epoch 4/100
508/508 - 0s - loss: 0.1374 - mse: 0.1374 - val_loss: 0.1153 - val_mse: 0.1153
Epoch 5/100
508/508 - 0s - loss: 0.1078 - mse: 0.1078 - val_loss: 0.0998 - val_mse: 0.0998
Epoch 6/100
508/508 - 0s - loss: 0.0921 - mse: 0.0921 - val_loss: 0.0827 - val_mse: 0.0827
Epoch 7/100
508/508 - 0s - loss: 0.0792 - mse: 0.0792 - val_loss: 0.0718 - val_mse: 0.0718
Epoch 8/100
508/508 - 0s - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0606 - val_mse: 0.0606
Epoch 9/100
508/508 - 0s - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0556 - val_mse: 0.0556
Epoch 10/100
508/508 - 0s - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0533 - val_mse: 0.0533
Epoch 11/100
508/508 - 0s - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0498 - val_mse: 0.0498
Epoch 12/100
508/508 - 0s - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0513 - val_mse: 0.0513
Epoch 13/100
508/508 - 0s - loss: 0.0443 - mse: 0.0443 - val_loss: 0.0432 - val_mse: 0.0432
Epoch 14/100
508/508 - 0s - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0425 - val_mse: 0.0425
Epoch 15/100
508/508 - 0s - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0404 - val_mse: 0.0404
Epoch 16/100
508/508 - 0s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0396 - val_mse: 0.0396
Epoch 17/100
508/508 - 0s - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0374 - val_mse: 0.0374
Epoch 18/100
508/508 - 0s - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0382 - val_mse: 0.0382
Epoch 19/100
508/508 - 0s - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0370 - val_mse: 0.0370
Epoch 20/100
508/508 - 0s - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0365 - val_mse: 0.0365
Epoch 21/100
508/508 - 0s - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 22/100
508/508 - 0s - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0332 - val_mse: 0.0332
Epoch 23/100
508/508 - 0s - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 24/100
508/508 - 0s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0324 - val_mse: 0.0324
Epoch 25/100
508/508 - 0s - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 26/100
508/508 - 0s - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 27/100
508/508 - 0s - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 28/100
508/508 - 0s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0273 - val_mse: 0.0273
Epoch 29/100
508/508 - 0s - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0264 - val_mse: 0.0264
Epoch 30/100
508/508 - 0s - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0269 - val_mse: 0.0269
Epoch 31/100
508/508 - 0s - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 32/100
508/508 - 0s - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 33/100
508/508 - 0s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0235 - val_mse: 0.0235
Epoch 34/100
508/508 - 0s - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0246 - val_mse: 0.0246
Epoch 35/100
508/508 - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0223 - val_mse: 0.0223
Epoch 36/100
508/508 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 37/100
508/508 - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0224 - val_mse: 0.0224
Epoch 38/100
508/508 - 0s - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0227 - val_mse: 0.0227
Epoch 39/100
508/508 - 0s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 40/100
508/508 - 0s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0196 - val_mse: 0.0196
Epoch 41/100
508/508 - 0s - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0191 - val_mse: 0.0191
Epoch 42/100
508/508 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0180 - val_mse: 0.0180
Epoch 43/100
508/508 - 0s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0184 - val_mse: 0.0184
Epoch 44/100
508/508 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0182 - val_mse: 0.0182
Epoch 45/100
508/508 - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0173 - val_mse: 0.0173
Epoch 46/100
508/508 - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 47/100
508/508 - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 48/100
508/508 - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0173 - val_mse: 0.0173
Epoch 49/100
508/508 - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0164 - val_mse: 0.0164
Epoch 50/100
508/508 - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0161 - val_mse: 0.0161
Epoch 51/100
508/508 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0157 - val_mse: 0.0157
Epoch 52/100
508/508 - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 53/100
508/508 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0153 - val_mse: 0.0153
Epoch 54/100
508/508 - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0153 - val_mse: 0.0153
Epoch 55/100
508/508 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 56/100
508/508 - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 57/100
508/508 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 58/100
508/508 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 59/100
508/508 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 60/100
508/508 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 61/100
508/508 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 62/100
508/508 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 63/100
508/508 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 64/100
508/508 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 65/100
508/508 - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 66/100
508/508 - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 67/100
508/508 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 68/100
508/508 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 69/100
508/508 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 70/100
508/508 - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 71/100
508/508 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 72/100
508/508 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 73/100
508/508 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 74/100
508/508 - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 75/100
508/508 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0135 - val_mse: 0.0135
Epoch 76/100
508/508 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 77/100
508/508 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0135 - val_mse: 0.0135
Epoch 78/100
508/508 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0139 - val_mse: 0.0139
Epoch 79/100
508/508 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 80/100
508/508 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0134 - val_mse: 0.0134
Epoch 81/100
508/508 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 82/100
508/508 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0133 - val_mse: 0.0133
Epoch 83/100
508/508 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 84/100
508/508 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0132 - val_mse: 0.0132
Epoch 85/100
508/508 - 0s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 86/100
508/508 - 0s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0135 - val_mse: 0.0135
saving model CNNxySTOCHASTIC7
model 8/120
time elapsed:
00:04:38.94
estimated time left:
01:05:05.13 


STOCHASTIC run: 8
Train on 428 samples, validate on 107 samples
Epoch 1/100
428/428 - 2s - loss: 0.1861 - mse: 0.1861 - val_loss: 0.1741 - val_mse: 0.1741
Epoch 2/100
428/428 - 0s - loss: 0.1536 - mse: 0.1536 - val_loss: 0.1413 - val_mse: 0.1413
Epoch 3/100
428/428 - 0s - loss: 0.1312 - mse: 0.1312 - val_loss: 0.1313 - val_mse: 0.1313
Epoch 4/100
428/428 - 0s - loss: 0.1183 - mse: 0.1183 - val_loss: 0.1282 - val_mse: 0.1282
Epoch 5/100
428/428 - 0s - loss: 0.1106 - mse: 0.1106 - val_loss: 0.1146 - val_mse: 0.1146
Epoch 6/100
428/428 - 0s - loss: 0.1000 - mse: 0.1000 - val_loss: 0.1066 - val_mse: 0.1066
Epoch 7/100
428/428 - 0s - loss: 0.0868 - mse: 0.0868 - val_loss: 0.0930 - val_mse: 0.0930
Epoch 8/100
428/428 - 0s - loss: 0.0710 - mse: 0.0710 - val_loss: 0.0779 - val_mse: 0.0779
Epoch 9/100
428/428 - 0s - loss: 0.0605 - mse: 0.0605 - val_loss: 0.0657 - val_mse: 0.0657
Epoch 10/100
428/428 - 0s - loss: 0.0525 - mse: 0.0525 - val_loss: 0.0657 - val_mse: 0.0657
Epoch 11/100
428/428 - 0s - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0582 - val_mse: 0.0582
Epoch 12/100
428/428 - 0s - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0557 - val_mse: 0.0557
Epoch 13/100
428/428 - 0s - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0555 - val_mse: 0.0555
Epoch 14/100
428/428 - 0s - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0481 - val_mse: 0.0481
Epoch 15/100
428/428 - 0s - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0485 - val_mse: 0.0485
Epoch 16/100
428/428 - 0s - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0430 - val_mse: 0.0430
Epoch 17/100
428/428 - 0s - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0411 - val_mse: 0.0411
Epoch 18/100
428/428 - 0s - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0393 - val_mse: 0.0393
Epoch 19/100
428/428 - 0s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0377 - val_mse: 0.0377
Epoch 20/100
428/428 - 0s - loss: 0.0254 - mse: 0.0254 - val_loss: 0.0346 - val_mse: 0.0346
Epoch 21/100
428/428 - 0s - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0325 - val_mse: 0.0325
Epoch 22/100
428/428 - 0s - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0338 - val_mse: 0.0338
Epoch 23/100
428/428 - 0s - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0308 - val_mse: 0.0308
Epoch 24/100
428/428 - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0301 - val_mse: 0.0301
Epoch 25/100
428/428 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 26/100
428/428 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0290 - val_mse: 0.0290
Epoch 27/100
428/428 - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0281 - val_mse: 0.0281
Epoch 28/100
428/428 - 0s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0260 - val_mse: 0.0260
Epoch 29/100
428/428 - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0262 - val_mse: 0.0262
Epoch 30/100
428/428 - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 31/100
428/428 - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 32/100
428/428 - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0254 - val_mse: 0.0254
Epoch 33/100
428/428 - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 34/100
428/428 - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0257 - val_mse: 0.0257
Epoch 35/100
428/428 - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0228 - val_mse: 0.0228
Epoch 36/100
428/428 - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0258 - val_mse: 0.0258
Epoch 37/100
428/428 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0227 - val_mse: 0.0227
Epoch 38/100
428/428 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0226 - val_mse: 0.0226
Epoch 39/100
428/428 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0238 - val_mse: 0.0238
Epoch 40/100
428/428 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0219 - val_mse: 0.0219
Epoch 41/100
428/428 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0221 - val_mse: 0.0221
Epoch 42/100
428/428 - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0233 - val_mse: 0.0233
Epoch 43/100
428/428 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 44/100
428/428 - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 45/100
428/428 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0213 - val_mse: 0.0213
Epoch 46/100
428/428 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0225 - val_mse: 0.0225
Epoch 47/100
428/428 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 48/100
428/428 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0213 - val_mse: 0.0213
Epoch 49/100
428/428 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 50/100
428/428 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0212 - val_mse: 0.0212
Epoch 51/100
428/428 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0213 - val_mse: 0.0213
Epoch 52/100
428/428 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0210 - val_mse: 0.0210
Epoch 53/100
428/428 - 0s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0208 - val_mse: 0.0208
Epoch 54/100
428/428 - 0s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0225 - val_mse: 0.0225
Epoch 55/100
428/428 - 0s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0213 - val_mse: 0.0213
Epoch 56/100
428/428 - 0s - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 57/100
428/428 - 0s - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 58/100
428/428 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 59/100
428/428 - 0s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0224 - val_mse: 0.0224
Epoch 60/100
428/428 - 0s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 61/100
428/428 - 0s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0210 - val_mse: 0.0210
Epoch 62/100
428/428 - 0s - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 63/100
428/428 - 0s - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0220 - val_mse: 0.0220
saving model CNNxySTOCHASTIC8
model 9/120
time elapsed:
00:04:58.30
estimated time left:
01:01:19.02 


STOCHASTIC run: 9
Train on 348 samples, validate on 87 samples
Epoch 1/100
348/348 - 1s - loss: 0.7521 - mse: 0.7521 - val_loss: 0.3828 - val_mse: 0.3828
Epoch 2/100
348/348 - 0s - loss: 0.2676 - mse: 0.2676 - val_loss: 0.1968 - val_mse: 0.1968
Epoch 3/100
348/348 - 0s - loss: 0.1879 - mse: 0.1879 - val_loss: 0.1906 - val_mse: 0.1906
Epoch 4/100
348/348 - 0s - loss: 0.1900 - mse: 0.1900 - val_loss: 0.1941 - val_mse: 0.1941
Epoch 5/100
348/348 - 0s - loss: 0.1932 - mse: 0.1932 - val_loss: 0.1934 - val_mse: 0.1934
Epoch 6/100
348/348 - 0s - loss: 0.1897 - mse: 0.1897 - val_loss: 0.1881 - val_mse: 0.1881
Epoch 7/100
348/348 - 0s - loss: 0.1839 - mse: 0.1839 - val_loss: 0.1833 - val_mse: 0.1833
Epoch 8/100
348/348 - 0s - loss: 0.1786 - mse: 0.1786 - val_loss: 0.1796 - val_mse: 0.1796
Epoch 9/100
348/348 - 0s - loss: 0.1741 - mse: 0.1741 - val_loss: 0.1754 - val_mse: 0.1754
Epoch 10/100
348/348 - 0s - loss: 0.1675 - mse: 0.1675 - val_loss: 0.1672 - val_mse: 0.1672
Epoch 11/100
348/348 - 0s - loss: 0.1607 - mse: 0.1607 - val_loss: 0.1582 - val_mse: 0.1582
Epoch 12/100
348/348 - 0s - loss: 0.1532 - mse: 0.1532 - val_loss: 0.1511 - val_mse: 0.1511
Epoch 13/100
348/348 - 0s - loss: 0.1453 - mse: 0.1453 - val_loss: 0.1427 - val_mse: 0.1427
Epoch 14/100
348/348 - 0s - loss: 0.1382 - mse: 0.1382 - val_loss: 0.1342 - val_mse: 0.1342
Epoch 15/100
348/348 - 0s - loss: 0.1298 - mse: 0.1298 - val_loss: 0.1274 - val_mse: 0.1274
Epoch 16/100
348/348 - 0s - loss: 0.1233 - mse: 0.1233 - val_loss: 0.1190 - val_mse: 0.1190
Epoch 17/100
348/348 - 0s - loss: 0.1178 - mse: 0.1178 - val_loss: 0.1142 - val_mse: 0.1142
Epoch 18/100
348/348 - 0s - loss: 0.1116 - mse: 0.1116 - val_loss: 0.1108 - val_mse: 0.1108
Epoch 19/100
348/348 - 0s - loss: 0.1074 - mse: 0.1074 - val_loss: 0.1072 - val_mse: 0.1072
Epoch 20/100
348/348 - 0s - loss: 0.1033 - mse: 0.1033 - val_loss: 0.1022 - val_mse: 0.1022
Epoch 21/100
348/348 - 0s - loss: 0.0992 - mse: 0.0992 - val_loss: 0.1002 - val_mse: 0.1002
Epoch 22/100
348/348 - 0s - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0942 - val_mse: 0.0942
Epoch 23/100
348/348 - 0s - loss: 0.0905 - mse: 0.0905 - val_loss: 0.0921 - val_mse: 0.0921
Epoch 24/100
348/348 - 0s - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0860 - val_mse: 0.0860
Epoch 25/100
348/348 - 0s - loss: 0.0807 - mse: 0.0807 - val_loss: 0.0839 - val_mse: 0.0839
Epoch 26/100
348/348 - 0s - loss: 0.0769 - mse: 0.0769 - val_loss: 0.0769 - val_mse: 0.0769
Epoch 27/100
348/348 - 0s - loss: 0.0732 - mse: 0.0732 - val_loss: 0.0754 - val_mse: 0.0754
Epoch 28/100
348/348 - 0s - loss: 0.0698 - mse: 0.0698 - val_loss: 0.0728 - val_mse: 0.0728
Epoch 29/100
348/348 - 0s - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0680 - val_mse: 0.0680
Epoch 30/100
348/348 - 0s - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0651 - val_mse: 0.0651
Epoch 31/100
348/348 - 0s - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0635 - val_mse: 0.0635
Epoch 32/100
348/348 - 0s - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0642 - val_mse: 0.0642
Epoch 33/100
348/348 - 0s - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0675 - val_mse: 0.0675
Epoch 34/100
348/348 - 0s - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0596 - val_mse: 0.0596
Epoch 35/100
348/348 - 0s - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0579 - val_mse: 0.0579
Epoch 36/100
348/348 - 0s - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0549 - val_mse: 0.0549
Epoch 37/100
348/348 - 0s - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0562 - val_mse: 0.0562
Epoch 38/100
348/348 - 0s - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0496 - val_mse: 0.0496
Epoch 39/100
348/348 - 0s - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0505 - val_mse: 0.0505
Epoch 40/100
348/348 - 0s - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0520 - val_mse: 0.0520
Epoch 41/100
348/348 - 0s - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0468 - val_mse: 0.0468
Epoch 42/100
348/348 - 0s - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0474 - val_mse: 0.0474
Epoch 43/100
348/348 - 0s - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0417 - val_mse: 0.0417
Epoch 44/100
348/348 - 0s - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0428 - val_mse: 0.0428
Epoch 45/100
348/348 - 0s - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0475 - val_mse: 0.0475
Epoch 46/100
348/348 - 0s - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0416 - val_mse: 0.0416
Epoch 47/100
348/348 - 0s - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0391 - val_mse: 0.0391
Epoch 48/100
348/348 - 0s - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0446 - val_mse: 0.0446
Epoch 49/100
348/348 - 0s - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0370 - val_mse: 0.0370
Epoch 50/100
348/348 - 0s - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0408 - val_mse: 0.0408
Epoch 51/100
348/348 - 0s - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0358 - val_mse: 0.0358
Epoch 52/100
348/348 - 0s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0343 - val_mse: 0.0343
Epoch 53/100
348/348 - 0s - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0384 - val_mse: 0.0384
Epoch 54/100
348/348 - 0s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0334 - val_mse: 0.0334
Epoch 55/100
348/348 - 0s - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0365 - val_mse: 0.0365
Epoch 56/100
348/348 - 0s - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0381 - val_mse: 0.0381
Epoch 57/100
348/348 - 0s - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0455 - val_mse: 0.0455
Epoch 58/100
348/348 - 0s - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0331 - val_mse: 0.0331
Epoch 59/100
348/348 - 0s - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0336 - val_mse: 0.0336
Epoch 60/100
348/348 - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0329 - val_mse: 0.0329
Epoch 61/100
348/348 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0346 - val_mse: 0.0346
Epoch 62/100
348/348 - 0s - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0332 - val_mse: 0.0332
Epoch 63/100
348/348 - 0s - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0332 - val_mse: 0.0332
Epoch 64/100
348/348 - 0s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0347 - val_mse: 0.0347
Epoch 65/100
348/348 - 0s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0345 - val_mse: 0.0345
Epoch 66/100
348/348 - 0s - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0336 - val_mse: 0.0336
Epoch 67/100
348/348 - 0s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0345 - val_mse: 0.0345
Epoch 68/100
348/348 - 0s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0358 - val_mse: 0.0358
Epoch 69/100
348/348 - 0s - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0319 - val_mse: 0.0319
Epoch 70/100
348/348 - 0s - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0494 - val_mse: 0.0494
Epoch 71/100
348/348 - 0s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0332 - val_mse: 0.0332
Epoch 72/100
348/348 - 0s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0353 - val_mse: 0.0353
Epoch 73/100
348/348 - 0s - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0323 - val_mse: 0.0323
Epoch 74/100
348/348 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0373 - val_mse: 0.0373
Epoch 75/100
348/348 - 0s - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0356 - val_mse: 0.0356
Epoch 76/100
348/348 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0360 - val_mse: 0.0360
Epoch 77/100
348/348 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0355 - val_mse: 0.0355
Epoch 78/100
348/348 - 0s - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0367 - val_mse: 0.0367
Epoch 79/100
348/348 - 0s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0422 - val_mse: 0.0422
saving model CNNxySTOCHASTIC9
model 10/120
time elapsed:
00:05:17.05
estimated time left:
00:58:07.50 


STOCHASTIC run: 10
Train on 268 samples, validate on 67 samples
Epoch 1/100
268/268 - 1s - loss: 1.7851 - mse: 1.7851 - val_loss: 1.2762 - val_mse: 1.2762
Epoch 2/100
268/268 - 0s - loss: 1.0147 - mse: 1.0147 - val_loss: 0.6104 - val_mse: 0.6104
Epoch 3/100
268/268 - 0s - loss: 0.5137 - mse: 0.5137 - val_loss: 0.3874 - val_mse: 0.3874
Epoch 4/100
268/268 - 0s - loss: 0.3443 - mse: 0.3443 - val_loss: 0.2799 - val_mse: 0.2799
Epoch 5/100
268/268 - 0s - loss: 0.2515 - mse: 0.2515 - val_loss: 0.2249 - val_mse: 0.2249
Epoch 6/100
268/268 - 0s - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2003 - val_mse: 0.2003
Epoch 7/100
268/268 - 0s - loss: 0.1918 - mse: 0.1918 - val_loss: 0.1905 - val_mse: 0.1905
Epoch 8/100
268/268 - 0s - loss: 0.1872 - mse: 0.1872 - val_loss: 0.1886 - val_mse: 0.1886
Epoch 9/100
268/268 - 0s - loss: 0.1873 - mse: 0.1873 - val_loss: 0.1891 - val_mse: 0.1891
Epoch 10/100
268/268 - 0s - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1899 - val_mse: 0.1899
Epoch 11/100
268/268 - 0s - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1913 - val_mse: 0.1913
Epoch 12/100
268/268 - 0s - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1921 - val_mse: 0.1921
Epoch 13/100
268/268 - 0s - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 14/100
268/268 - 0s - loss: 0.1872 - mse: 0.1872 - val_loss: 0.1913 - val_mse: 0.1913
Epoch 15/100
268/268 - 0s - loss: 0.1869 - mse: 0.1869 - val_loss: 0.1910 - val_mse: 0.1910
Epoch 16/100
268/268 - 0s - loss: 0.1868 - mse: 0.1868 - val_loss: 0.1903 - val_mse: 0.1903
Epoch 17/100
268/268 - 0s - loss: 0.1867 - mse: 0.1867 - val_loss: 0.1905 - val_mse: 0.1905
Epoch 18/100
268/268 - 0s - loss: 0.1865 - mse: 0.1865 - val_loss: 0.1903 - val_mse: 0.1903
saving model CNNxySTOCHASTIC10
model 11/120
time elapsed:
00:05:21.78
estimated time left:
00:53:08.58 


STOCHASTIC run: 11
Train on 188 samples, validate on 47 samples
Epoch 1/100
188/188 - 1s - loss: 0.4690 - mse: 0.4690 - val_loss: 0.3698 - val_mse: 0.3698
Epoch 2/100
188/188 - 0s - loss: 0.3063 - mse: 0.3063 - val_loss: 0.2259 - val_mse: 0.2259
Epoch 3/100
188/188 - 0s - loss: 0.1970 - mse: 0.1970 - val_loss: 0.1911 - val_mse: 0.1911
Epoch 4/100
188/188 - 0s - loss: 0.1974 - mse: 0.1974 - val_loss: 0.2140 - val_mse: 0.2140
Epoch 5/100
188/188 - 0s - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2031 - val_mse: 0.2031
Epoch 6/100
188/188 - 0s - loss: 0.1936 - mse: 0.1936 - val_loss: 0.1846 - val_mse: 0.1846
Epoch 7/100
188/188 - 0s - loss: 0.1809 - mse: 0.1809 - val_loss: 0.1810 - val_mse: 0.1810
Epoch 8/100
188/188 - 0s - loss: 0.1733 - mse: 0.1733 - val_loss: 0.1790 - val_mse: 0.1790
Epoch 9/100
188/188 - 0s - loss: 0.1686 - mse: 0.1686 - val_loss: 0.1692 - val_mse: 0.1692
Epoch 10/100
188/188 - 0s - loss: 0.1571 - mse: 0.1571 - val_loss: 0.1611 - val_mse: 0.1611
Epoch 11/100
188/188 - 0s - loss: 0.1518 - mse: 0.1518 - val_loss: 0.1534 - val_mse: 0.1534
Epoch 12/100
188/188 - 0s - loss: 0.1417 - mse: 0.1417 - val_loss: 0.1427 - val_mse: 0.1427
Epoch 13/100
188/188 - 0s - loss: 0.1311 - mse: 0.1311 - val_loss: 0.1348 - val_mse: 0.1348
Epoch 14/100
188/188 - 0s - loss: 0.1210 - mse: 0.1210 - val_loss: 0.1255 - val_mse: 0.1255
Epoch 15/100
188/188 - 0s - loss: 0.1125 - mse: 0.1125 - val_loss: 0.1197 - val_mse: 0.1197
Epoch 16/100
188/188 - 0s - loss: 0.1074 - mse: 0.1074 - val_loss: 0.1175 - val_mse: 0.1175
Epoch 17/100
188/188 - 0s - loss: 0.1038 - mse: 0.1038 - val_loss: 0.1137 - val_mse: 0.1137
Epoch 18/100
188/188 - 0s - loss: 0.1029 - mse: 0.1029 - val_loss: 0.1073 - val_mse: 0.1073
Epoch 19/100
188/188 - 0s - loss: 0.0922 - mse: 0.0922 - val_loss: 0.1011 - val_mse: 0.1011
Epoch 20/100
188/188 - 0s - loss: 0.0865 - mse: 0.0865 - val_loss: 0.0915 - val_mse: 0.0915
Epoch 21/100
188/188 - 0s - loss: 0.0758 - mse: 0.0758 - val_loss: 0.0827 - val_mse: 0.0827
Epoch 22/100
188/188 - 0s - loss: 0.0676 - mse: 0.0676 - val_loss: 0.0763 - val_mse: 0.0763
Epoch 23/100
188/188 - 0s - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0721 - val_mse: 0.0721
Epoch 24/100
188/188 - 0s - loss: 0.0534 - mse: 0.0534 - val_loss: 0.0698 - val_mse: 0.0698
Epoch 25/100
188/188 - 0s - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0698 - val_mse: 0.0698
Epoch 26/100
188/188 - 0s - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0689 - val_mse: 0.0689
Epoch 27/100
188/188 - 0s - loss: 0.0475 - mse: 0.0475 - val_loss: 0.0654 - val_mse: 0.0654
Epoch 28/100
188/188 - 0s - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0637 - val_mse: 0.0637
Epoch 29/100
188/188 - 0s - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0628 - val_mse: 0.0628
Epoch 30/100
188/188 - 0s - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0609 - val_mse: 0.0609
Epoch 31/100
188/188 - 0s - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0595 - val_mse: 0.0595
Epoch 32/100
188/188 - 0s - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0591 - val_mse: 0.0591
Epoch 33/100
188/188 - 0s - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0565 - val_mse: 0.0565
Epoch 34/100
188/188 - 0s - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0559 - val_mse: 0.0559
Epoch 35/100
188/188 - 0s - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0550 - val_mse: 0.0550
Epoch 36/100
188/188 - 0s - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0545 - val_mse: 0.0545
Epoch 37/100
188/188 - 0s - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0537 - val_mse: 0.0537
Epoch 38/100
188/188 - 0s - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0530 - val_mse: 0.0530
Epoch 39/100
188/188 - 0s - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0520 - val_mse: 0.0520
Epoch 40/100
188/188 - 0s - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0515 - val_mse: 0.0515
Epoch 41/100
188/188 - 0s - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0520 - val_mse: 0.0520
Epoch 42/100
188/188 - 0s - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0503 - val_mse: 0.0503
Epoch 43/100
188/188 - 0s - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0507 - val_mse: 0.0507
Epoch 44/100
188/188 - 0s - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0494 - val_mse: 0.0494
Epoch 45/100
188/188 - 0s - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0499 - val_mse: 0.0499
Epoch 46/100
188/188 - 0s - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0490 - val_mse: 0.0490
Epoch 47/100
188/188 - 0s - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0484 - val_mse: 0.0484
Epoch 48/100
188/188 - 0s - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0498 - val_mse: 0.0498
Epoch 49/100
188/188 - 0s - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0491 - val_mse: 0.0491
Epoch 50/100
188/188 - 0s - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0486 - val_mse: 0.0486
Epoch 51/100
188/188 - 0s - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0478 - val_mse: 0.0478
Epoch 52/100
188/188 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0492 - val_mse: 0.0492
Epoch 53/100
188/188 - 0s - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0511 - val_mse: 0.0511
Epoch 54/100
188/188 - 0s - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0472 - val_mse: 0.0472
Epoch 55/100
188/188 - 0s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0472 - val_mse: 0.0472
Epoch 56/100
188/188 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0477 - val_mse: 0.0477
Epoch 57/100
188/188 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0462 - val_mse: 0.0462
Epoch 58/100
188/188 - 0s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0461 - val_mse: 0.0461
Epoch 59/100
188/188 - 0s - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0474 - val_mse: 0.0474
Epoch 60/100
188/188 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0455 - val_mse: 0.0455
Epoch 61/100
188/188 - 0s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0450 - val_mse: 0.0450
Epoch 62/100
188/188 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0461 - val_mse: 0.0461
Epoch 63/100
188/188 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0444 - val_mse: 0.0444
Epoch 64/100
188/188 - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0438 - val_mse: 0.0438
Epoch 65/100
188/188 - 0s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0449 - val_mse: 0.0449
Epoch 66/100
188/188 - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0439 - val_mse: 0.0439
Epoch 67/100
188/188 - 0s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0440 - val_mse: 0.0440
Epoch 68/100
188/188 - 0s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0437 - val_mse: 0.0437
Epoch 69/100
188/188 - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0433 - val_mse: 0.0433
Epoch 70/100
188/188 - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0439 - val_mse: 0.0439
Epoch 71/100
188/188 - 0s - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0426 - val_mse: 0.0426
Epoch 72/100
188/188 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0422 - val_mse: 0.0422
Epoch 73/100
188/188 - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0416 - val_mse: 0.0416
Epoch 74/100
188/188 - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0416 - val_mse: 0.0416
Epoch 75/100
188/188 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0411 - val_mse: 0.0411
Epoch 76/100
188/188 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0410 - val_mse: 0.0410
Epoch 77/100
188/188 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0408 - val_mse: 0.0408
Epoch 78/100
188/188 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0408 - val_mse: 0.0408
Epoch 79/100
188/188 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0402 - val_mse: 0.0402
Epoch 80/100
188/188 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0400 - val_mse: 0.0400
Epoch 81/100
188/188 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0399 - val_mse: 0.0399
Epoch 82/100
188/188 - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0397 - val_mse: 0.0397
Epoch 83/100
188/188 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0399 - val_mse: 0.0399
Epoch 84/100
188/188 - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0393 - val_mse: 0.0393
Epoch 85/100
188/188 - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0394 - val_mse: 0.0394
Epoch 86/100
188/188 - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0392 - val_mse: 0.0392
Epoch 87/100
188/188 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0390 - val_mse: 0.0390
Epoch 88/100
188/188 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0389 - val_mse: 0.0389
Epoch 89/100
188/188 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0388 - val_mse: 0.0388
Epoch 90/100
188/188 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0388 - val_mse: 0.0388
Epoch 91/100
188/188 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0387 - val_mse: 0.0387
Epoch 92/100
188/188 - 0s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0387 - val_mse: 0.0387
Epoch 93/100
188/188 - 0s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0387 - val_mse: 0.0387
Epoch 94/100
188/188 - 0s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0384 - val_mse: 0.0384
Epoch 95/100
188/188 - 0s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0385 - val_mse: 0.0385
Epoch 96/100
188/188 - 0s - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0385 - val_mse: 0.0385
Epoch 97/100
188/188 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0386 - val_mse: 0.0386
Epoch 98/100
188/188 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0387 - val_mse: 0.0387
Epoch 99/100
188/188 - 0s - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0387 - val_mse: 0.0387
Epoch 100/100
188/188 - 0s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0386 - val_mse: 0.0386
saving model CNNxySTOCHASTIC11
model 12/120
time elapsed:
00:05:35.63
estimated time left:
00:50:20.67 


STOCHASTIC run: 12
Train on 108 samples, validate on 27 samples
Epoch 1/100
108/108 - 1s - loss: 1.0905 - mse: 1.0905 - val_loss: 1.0082 - val_mse: 1.0082
Epoch 2/100
108/108 - 0s - loss: 0.8989 - mse: 0.8989 - val_loss: 0.8091 - val_mse: 0.8091
Epoch 3/100
108/108 - 0s - loss: 0.7044 - mse: 0.7044 - val_loss: 0.6071 - val_mse: 0.6071
Epoch 4/100
108/108 - 0s - loss: 0.5174 - mse: 0.5174 - val_loss: 0.4295 - val_mse: 0.4295
Epoch 5/100
108/108 - 0s - loss: 0.3611 - mse: 0.3611 - val_loss: 0.3081 - val_mse: 0.3081
Epoch 6/100
108/108 - 0s - loss: 0.2714 - mse: 0.2714 - val_loss: 0.2471 - val_mse: 0.2471
Epoch 7/100
108/108 - 0s - loss: 0.2297 - mse: 0.2297 - val_loss: 0.2202 - val_mse: 0.2202
Epoch 8/100
108/108 - 0s - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2064 - val_mse: 0.2064
Epoch 9/100
108/108 - 0s - loss: 0.2029 - mse: 0.2029 - val_loss: 0.1979 - val_mse: 0.1979
Epoch 10/100
108/108 - 0s - loss: 0.1967 - mse: 0.1967 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 11/100
108/108 - 0s - loss: 0.1936 - mse: 0.1936 - val_loss: 0.1864 - val_mse: 0.1864
Epoch 12/100
108/108 - 0s - loss: 0.1919 - mse: 0.1919 - val_loss: 0.1844 - val_mse: 0.1844
Epoch 13/100
108/108 - 0s - loss: 0.1924 - mse: 0.1924 - val_loss: 0.1848 - val_mse: 0.1848
Epoch 14/100
108/108 - 0s - loss: 0.1953 - mse: 0.1953 - val_loss: 0.1839 - val_mse: 0.1839
Epoch 15/100
108/108 - 0s - loss: 0.1947 - mse: 0.1947 - val_loss: 0.1816 - val_mse: 0.1816
Epoch 16/100
108/108 - 0s - loss: 0.1923 - mse: 0.1923 - val_loss: 0.1800 - val_mse: 0.1800
Epoch 17/100
108/108 - 0s - loss: 0.1899 - mse: 0.1899 - val_loss: 0.1799 - val_mse: 0.1799
Epoch 18/100
108/108 - 0s - loss: 0.1891 - mse: 0.1891 - val_loss: 0.1799 - val_mse: 0.1799
Epoch 19/100
108/108 - 0s - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1791 - val_mse: 0.1791
Epoch 20/100
108/108 - 0s - loss: 0.1860 - mse: 0.1860 - val_loss: 0.1772 - val_mse: 0.1772
Epoch 21/100
108/108 - 0s - loss: 0.1829 - mse: 0.1829 - val_loss: 0.1741 - val_mse: 0.1741
Epoch 22/100
108/108 - 0s - loss: 0.1780 - mse: 0.1780 - val_loss: 0.1683 - val_mse: 0.1683
Epoch 23/100
108/108 - 0s - loss: 0.1686 - mse: 0.1686 - val_loss: 0.1640 - val_mse: 0.1640
Epoch 24/100
108/108 - 0s - loss: 0.1650 - mse: 0.1650 - val_loss: 0.1617 - val_mse: 0.1617
Epoch 25/100
108/108 - 0s - loss: 0.1589 - mse: 0.1589 - val_loss: 0.1540 - val_mse: 0.1540
Epoch 26/100
108/108 - 0s - loss: 0.1503 - mse: 0.1503 - val_loss: 0.1529 - val_mse: 0.1529
Epoch 27/100
108/108 - 0s - loss: 0.1463 - mse: 0.1463 - val_loss: 0.1481 - val_mse: 0.1481
Epoch 28/100
108/108 - 0s - loss: 0.1402 - mse: 0.1402 - val_loss: 0.1464 - val_mse: 0.1464
Epoch 29/100
108/108 - 0s - loss: 0.1351 - mse: 0.1351 - val_loss: 0.1429 - val_mse: 0.1429
Epoch 30/100
108/108 - 0s - loss: 0.1299 - mse: 0.1299 - val_loss: 0.1417 - val_mse: 0.1417
Epoch 31/100
108/108 - 0s - loss: 0.1277 - mse: 0.1277 - val_loss: 0.1383 - val_mse: 0.1383
Epoch 32/100
108/108 - 0s - loss: 0.1238 - mse: 0.1238 - val_loss: 0.1363 - val_mse: 0.1363
Epoch 33/100
108/108 - 0s - loss: 0.1225 - mse: 0.1225 - val_loss: 0.1343 - val_mse: 0.1343
Epoch 34/100
108/108 - 0s - loss: 0.1208 - mse: 0.1208 - val_loss: 0.1324 - val_mse: 0.1324
Epoch 35/100
108/108 - 0s - loss: 0.1187 - mse: 0.1187 - val_loss: 0.1304 - val_mse: 0.1304
Epoch 36/100
108/108 - 0s - loss: 0.1172 - mse: 0.1172 - val_loss: 0.1280 - val_mse: 0.1280
Epoch 37/100
108/108 - 0s - loss: 0.1160 - mse: 0.1160 - val_loss: 0.1263 - val_mse: 0.1263
Epoch 38/100
108/108 - 0s - loss: 0.1150 - mse: 0.1150 - val_loss: 0.1248 - val_mse: 0.1248
Epoch 39/100
108/108 - 0s - loss: 0.1147 - mse: 0.1147 - val_loss: 0.1238 - val_mse: 0.1238
Epoch 40/100
108/108 - 0s - loss: 0.1132 - mse: 0.1132 - val_loss: 0.1221 - val_mse: 0.1221
Epoch 41/100
108/108 - 0s - loss: 0.1109 - mse: 0.1109 - val_loss: 0.1210 - val_mse: 0.1210
Epoch 42/100
108/108 - 0s - loss: 0.1100 - mse: 0.1100 - val_loss: 0.1208 - val_mse: 0.1208
Epoch 43/100
108/108 - 0s - loss: 0.1091 - mse: 0.1091 - val_loss: 0.1194 - val_mse: 0.1194
Epoch 44/100
108/108 - 0s - loss: 0.1077 - mse: 0.1077 - val_loss: 0.1190 - val_mse: 0.1190
Epoch 45/100
108/108 - 0s - loss: 0.1065 - mse: 0.1065 - val_loss: 0.1186 - val_mse: 0.1186
Epoch 46/100
108/108 - 0s - loss: 0.1054 - mse: 0.1054 - val_loss: 0.1185 - val_mse: 0.1185
Epoch 47/100
108/108 - 0s - loss: 0.1050 - mse: 0.1050 - val_loss: 0.1178 - val_mse: 0.1178
Epoch 48/100
108/108 - 0s - loss: 0.1036 - mse: 0.1036 - val_loss: 0.1167 - val_mse: 0.1167
Epoch 49/100
108/108 - 0s - loss: 0.1023 - mse: 0.1023 - val_loss: 0.1164 - val_mse: 0.1164
Epoch 50/100
108/108 - 0s - loss: 0.1012 - mse: 0.1012 - val_loss: 0.1141 - val_mse: 0.1141
Epoch 51/100
108/108 - 0s - loss: 0.1019 - mse: 0.1019 - val_loss: 0.1128 - val_mse: 0.1128
Epoch 52/100
108/108 - 0s - loss: 0.0973 - mse: 0.0973 - val_loss: 0.1151 - val_mse: 0.1151
Epoch 53/100
108/108 - 0s - loss: 0.0993 - mse: 0.0993 - val_loss: 0.1111 - val_mse: 0.1111
Epoch 54/100
108/108 - 0s - loss: 0.0989 - mse: 0.0989 - val_loss: 0.1110 - val_mse: 0.1110
Epoch 55/100
108/108 - 0s - loss: 0.0964 - mse: 0.0964 - val_loss: 0.1168 - val_mse: 0.1168
Epoch 56/100
108/108 - 0s - loss: 0.0970 - mse: 0.0970 - val_loss: 0.1104 - val_mse: 0.1104
Epoch 57/100
108/108 - 0s - loss: 0.0923 - mse: 0.0923 - val_loss: 0.1103 - val_mse: 0.1103
Epoch 58/100
108/108 - 0s - loss: 0.0937 - mse: 0.0937 - val_loss: 0.1089 - val_mse: 0.1089
Epoch 59/100
108/108 - 0s - loss: 0.0905 - mse: 0.0905 - val_loss: 0.1066 - val_mse: 0.1066
Epoch 60/100
108/108 - 0s - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1046 - val_mse: 0.1046
Epoch 61/100
108/108 - 0s - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1048 - val_mse: 0.1048
Epoch 62/100
108/108 - 0s - loss: 0.0861 - mse: 0.0861 - val_loss: 0.1024 - val_mse: 0.1024
Epoch 63/100
108/108 - 0s - loss: 0.0839 - mse: 0.0839 - val_loss: 0.1011 - val_mse: 0.1011
Epoch 64/100
108/108 - 0s - loss: 0.0830 - mse: 0.0830 - val_loss: 0.1001 - val_mse: 0.1001
Epoch 65/100
108/108 - 0s - loss: 0.0811 - mse: 0.0811 - val_loss: 0.0977 - val_mse: 0.0977
Epoch 66/100
108/108 - 0s - loss: 0.0799 - mse: 0.0799 - val_loss: 0.0986 - val_mse: 0.0986
Epoch 67/100
108/108 - 0s - loss: 0.0798 - mse: 0.0798 - val_loss: 0.0955 - val_mse: 0.0955
Epoch 68/100
108/108 - 0s - loss: 0.0772 - mse: 0.0772 - val_loss: 0.0932 - val_mse: 0.0932
Epoch 69/100
108/108 - 0s - loss: 0.0745 - mse: 0.0745 - val_loss: 0.0959 - val_mse: 0.0959
Epoch 70/100
108/108 - 0s - loss: 0.0742 - mse: 0.0742 - val_loss: 0.0889 - val_mse: 0.0889
Epoch 71/100
108/108 - 0s - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0877 - val_mse: 0.0877
Epoch 72/100
108/108 - 0s - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0907 - val_mse: 0.0907
Epoch 73/100
108/108 - 0s - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0842 - val_mse: 0.0842
Epoch 74/100
108/108 - 0s - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0820 - val_mse: 0.0820
Epoch 75/100
108/108 - 0s - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0885 - val_mse: 0.0885
Epoch 76/100
108/108 - 0s - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0781 - val_mse: 0.0781
Epoch 77/100
108/108 - 0s - loss: 0.0632 - mse: 0.0632 - val_loss: 0.0755 - val_mse: 0.0755
Epoch 78/100
108/108 - 0s - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0812 - val_mse: 0.0812
Epoch 79/100
108/108 - 0s - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0733 - val_mse: 0.0733
Epoch 80/100
108/108 - 0s - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0732 - val_mse: 0.0732
Epoch 81/100
108/108 - 0s - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0748 - val_mse: 0.0748
Epoch 82/100
108/108 - 0s - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0699 - val_mse: 0.0699
Epoch 83/100
108/108 - 0s - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0730 - val_mse: 0.0730
Epoch 84/100
108/108 - 0s - loss: 0.0556 - mse: 0.0556 - val_loss: 0.0721 - val_mse: 0.0721
Epoch 85/100
108/108 - 0s - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0670 - val_mse: 0.0670
Epoch 86/100
108/108 - 0s - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0649 - val_mse: 0.0649
Epoch 87/100
108/108 - 0s - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0700 - val_mse: 0.0700
Epoch 88/100
108/108 - 0s - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0591 - val_mse: 0.0591
Epoch 89/100
108/108 - 0s - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0576 - val_mse: 0.0576
Epoch 90/100
108/108 - 0s - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0627 - val_mse: 0.0627
Epoch 91/100
108/108 - 0s - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0564 - val_mse: 0.0564
Epoch 92/100
108/108 - 0s - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0537 - val_mse: 0.0537
Epoch 93/100
108/108 - 0s - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0550 - val_mse: 0.0550
Epoch 94/100
108/108 - 0s - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0544 - val_mse: 0.0544
Epoch 95/100
108/108 - 0s - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0515 - val_mse: 0.0515
Epoch 96/100
108/108 - 0s - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0523 - val_mse: 0.0523
Epoch 97/100
108/108 - 0s - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0510 - val_mse: 0.0510
Epoch 98/100
108/108 - 0s - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0490 - val_mse: 0.0490
Epoch 99/100
108/108 - 0s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0509 - val_mse: 0.0509
Epoch 100/100
108/108 - 0s - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0494 - val_mse: 0.0494
saving model CNNxySTOCHASTIC12
model 13/120
time elapsed:
00:05:44.78
estimated time left:
00:47:17.77 


STOCHASTIC run: 13
Train on 28 samples, validate on 7 samples
Epoch 1/100
28/28 - 1s - loss: 0.7935 - mse: 0.7935 - val_loss: 0.6079 - val_mse: 0.6079
Epoch 2/100
28/28 - 0s - loss: 0.7056 - mse: 0.7056 - val_loss: 0.5363 - val_mse: 0.5363
Epoch 3/100
28/28 - 0s - loss: 0.6208 - mse: 0.6208 - val_loss: 0.4675 - val_mse: 0.4675
Epoch 4/100
28/28 - 0s - loss: 0.5367 - mse: 0.5367 - val_loss: 0.4030 - val_mse: 0.4030
Epoch 5/100
28/28 - 0s - loss: 0.4540 - mse: 0.4540 - val_loss: 0.3464 - val_mse: 0.3464
Epoch 6/100
28/28 - 0s - loss: 0.3757 - mse: 0.3757 - val_loss: 0.3018 - val_mse: 0.3018
Epoch 7/100
28/28 - 0s - loss: 0.3059 - mse: 0.3059 - val_loss: 0.2730 - val_mse: 0.2730
Epoch 8/100
28/28 - 0s - loss: 0.2494 - mse: 0.2494 - val_loss: 0.2615 - val_mse: 0.2615
Epoch 9/100
28/28 - 0s - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2637 - val_mse: 0.2637
Epoch 10/100
28/28 - 0s - loss: 0.1880 - mse: 0.1880 - val_loss: 0.2727 - val_mse: 0.2727
Epoch 11/100
28/28 - 0s - loss: 0.1792 - mse: 0.1792 - val_loss: 0.2828 - val_mse: 0.2828
Epoch 12/100
28/28 - 0s - loss: 0.1780 - mse: 0.1780 - val_loss: 0.2908 - val_mse: 0.2908
Epoch 13/100
28/28 - 0s - loss: 0.1799 - mse: 0.1799 - val_loss: 0.2957 - val_mse: 0.2957
Epoch 14/100
28/28 - 0s - loss: 0.1827 - mse: 0.1827 - val_loss: 0.2973 - val_mse: 0.2973
Epoch 15/100
28/28 - 0s - loss: 0.1853 - mse: 0.1853 - val_loss: 0.2960 - val_mse: 0.2960
Epoch 16/100
28/28 - 0s - loss: 0.1874 - mse: 0.1874 - val_loss: 0.2926 - val_mse: 0.2926
Epoch 17/100
28/28 - 0s - loss: 0.1892 - mse: 0.1892 - val_loss: 0.2883 - val_mse: 0.2883
Epoch 18/100
28/28 - 0s - loss: 0.1906 - mse: 0.1906 - val_loss: 0.2842 - val_mse: 0.2842
saving model CNNxySTOCHASTIC13
model 14/120
time elapsed:
00:05:46.99
estimated time left:
00:43:47.25 


STOCHASTIC run: 14
Traceback (most recent call last):
  File "train_models.py", line 255, in <module>
    run_experiments()
  File "train_models.py", line 205, in run_experiments
    model = build_model_xy(images[0].shape)
IndexError: index 0 is out of bounds for axis 0 with size 0


###############################################################################
Peregrine Cluster
Job 20848849 for user 'f118885'
Finished at: Thu Jul  1 10:04:29 CEST 2021

Job details:
============

Job ID              : 20848849
Name                : CNN_job
User                : f118885
Partition           : gpu
Nodes               : pg-gpu17
Number of Nodes     : 1
Cores               : 12
State               : FAILED
Submit              : 2021-07-01T09:05:42
Start               : 2021-07-01T09:58:30
End                 : 2021-07-01T10:04:29
Reserved walltime   : 02:15:00
Used walltime       : 00:05:59
Used CPU time       : 00:11:43 (efficiency: 16.33%)
% User (Computation): 93.16%
% System (I/O)      :  6.83%
Mem reserved        : 40G/node
Max Mem used        : 7.32G (pg-gpu17)
Max Disk Write      : 122.88K (pg-gpu17)
Max Disk Read       : 3.20M (pg-gpu17)
Average GPU usage   : 54.7% (pg-gpu17)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/introduction/scientific_output

################################################################################
