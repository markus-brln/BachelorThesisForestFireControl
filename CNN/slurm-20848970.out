
The following have been reloaded with a version change:
  1) FFTW/3.3.8-gompic-2019b => FFTW/3.3.8-gompi-2019b
  2) OpenMPI/3.1.4-gcccuda-2019b => OpenMPI/3.1.4-GCC-8.3.0
  3) ScaLAPACK/2.0.2-gompic-2019b => ScaLAPACK/2.0.2-gompi-2019b
  4) SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4 => SciPy-bundle/2019.10-foss-2019b-Python-3.7.4

Overview of modules that are loaded
starting CNN
2021-07-01 10:01:37.475024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
--------------------------------------------------------------------------
[[51096,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)
  Host: pg-gpu29

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
2021-07-01 10:01:44.938913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-07-01 10:01:44.948700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.948979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 32.00GiB deviceMemoryBandwidth: 836.37GiB/s
2021-07-01 10:01:44.949022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 10:01:44.953437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 10:01:44.956701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-07-01 10:01:44.958122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-07-01 10:01:44.961372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-07-01 10:01:44.963330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-07-01 10:01:44.968800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-07-01 10:01:44.968961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.969256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.969458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-07-01 10:01:44.972236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.972465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:02:00.0 name: GRID V100D-32Q computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 32.00GiB deviceMemoryBandwidth: 836.37GiB/s
2021-07-01 10:01:44.972515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 10:01:44.972545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 10:01:44.972566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-07-01 10:01:44.972604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-07-01 10:01:44.972625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-07-01 10:01:44.972646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-07-01 10:01:44.972666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-07-01 10:01:44.972754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.973014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:44.973204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-07-01 10:01:44.973246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-07-01 10:01:45.507952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-01 10:01:45.508037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2021-07-01 10:01:45.508054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2021-07-01 10:01:45.508315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:45.508698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:45.509004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-01 10:01:45.509229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 28652 MB memory) -> physical GPU (device: 0, name: GRID V100D-32Q, pci bus id: 0000:02:00.0, compute capability: 7.0)
2021-07-01 10:01:45.509561: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.
2021-07-01 10:01:47.115229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-07-01 10:01:47.392245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
loading data
input images:  (1435, 256, 256, 7)
outputs:  (1435, 3)
STOCHASTIC run: 0
Train on 1068 samples, validate on 267 samples
Epoch 1/100
1068/1068 - 3s - loss: 0.5203 - mse: 0.5203 - val_loss: 0.1928 - val_mse: 0.1928
Epoch 2/100
1068/1068 - 1s - loss: 0.1939 - mse: 0.1939 - val_loss: 0.2003 - val_mse: 0.2003
Epoch 3/100
1068/1068 - 1s - loss: 0.1865 - mse: 0.1865 - val_loss: 0.1860 - val_mse: 0.1860
Epoch 4/100
1068/1068 - 1s - loss: 0.1739 - mse: 0.1739 - val_loss: 0.1657 - val_mse: 0.1657
Epoch 5/100
1068/1068 - 1s - loss: 0.1499 - mse: 0.1499 - val_loss: 0.1473 - val_mse: 0.1473
Epoch 6/100
1068/1068 - 1s - loss: 0.1307 - mse: 0.1307 - val_loss: 0.1306 - val_mse: 0.1306
Epoch 7/100
1068/1068 - 1s - loss: 0.1168 - mse: 0.1168 - val_loss: 0.1214 - val_mse: 0.1214
Epoch 8/100
1068/1068 - 1s - loss: 0.1066 - mse: 0.1066 - val_loss: 0.1089 - val_mse: 0.1089
Epoch 9/100
1068/1068 - 1s - loss: 0.0960 - mse: 0.0960 - val_loss: 0.0985 - val_mse: 0.0985
Epoch 10/100
1068/1068 - 1s - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0896 - val_mse: 0.0896
Epoch 11/100
1068/1068 - 1s - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0814 - val_mse: 0.0814
Epoch 12/100
1068/1068 - 1s - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0759 - val_mse: 0.0759
Epoch 13/100
1068/1068 - 1s - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0680 - val_mse: 0.0680
Epoch 14/100
1068/1068 - 1s - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0656 - val_mse: 0.0656
Epoch 15/100
1068/1068 - 1s - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0583 - val_mse: 0.0583
Epoch 16/100
1068/1068 - 1s - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0536 - val_mse: 0.0536
Epoch 17/100
1068/1068 - 1s - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0523 - val_mse: 0.0523
Epoch 18/100
1068/1068 - 1s - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0469 - val_mse: 0.0469
Epoch 19/100
1068/1068 - 1s - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0459 - val_mse: 0.0459
Epoch 20/100
1068/1068 - 1s - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0425 - val_mse: 0.0425
Epoch 21/100
1068/1068 - 1s - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0392 - val_mse: 0.0392
Epoch 22/100
1068/1068 - 1s - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0382 - val_mse: 0.0382
Epoch 23/100
1068/1068 - 1s - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0364 - val_mse: 0.0364
Epoch 24/100
1068/1068 - 1s - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0355 - val_mse: 0.0355
Epoch 25/100
1068/1068 - 1s - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0336 - val_mse: 0.0336
Epoch 26/100
1068/1068 - 1s - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0335 - val_mse: 0.0335
Epoch 27/100
1068/1068 - 1s - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0325 - val_mse: 0.0325
Epoch 28/100
1068/1068 - 1s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0326 - val_mse: 0.0326
Epoch 29/100
1068/1068 - 1s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0312 - val_mse: 0.0312
Epoch 30/100
1068/1068 - 1s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 31/100
1068/1068 - 1s - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0306 - val_mse: 0.0306
Epoch 32/100
1068/1068 - 1s - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0305 - val_mse: 0.0305
Epoch 33/100
1068/1068 - 1s - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 34/100
1068/1068 - 1s - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0300 - val_mse: 0.0300
Epoch 35/100
1068/1068 - 1s - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 36/100
1068/1068 - 1s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0292 - val_mse: 0.0292
Epoch 37/100
1068/1068 - 1s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 38/100
1068/1068 - 1s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0293 - val_mse: 0.0293
Epoch 39/100
1068/1068 - 1s - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0284 - val_mse: 0.0284
Epoch 40/100
1068/1068 - 1s - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0303 - val_mse: 0.0303
Epoch 41/100
1068/1068 - 1s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 42/100
1068/1068 - 1s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 43/100
1068/1068 - 1s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0293 - val_mse: 0.0293
Epoch 44/100
1068/1068 - 1s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0276 - val_mse: 0.0276
Epoch 45/100
1068/1068 - 1s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0283 - val_mse: 0.0283
Epoch 46/100
1068/1068 - 1s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0288 - val_mse: 0.0288
Epoch 47/100
1068/1068 - 1s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0289 - val_mse: 0.0289
Epoch 48/100
1068/1068 - 1s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0271 - val_mse: 0.0271
Epoch 49/100
1068/1068 - 1s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0267 - val_mse: 0.0267
Epoch 50/100
1068/1068 - 1s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0301 - val_mse: 0.0301
Epoch 51/100
1068/1068 - 1s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0283 - val_mse: 0.0283
Epoch 52/100
1068/1068 - 1s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0258 - val_mse: 0.0258
Epoch 53/100
1068/1068 - 1s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0283 - val_mse: 0.0283
Epoch 54/100
1068/1068 - 1s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0280 - val_mse: 0.0280
Epoch 55/100
1068/1068 - 1s - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0265 - val_mse: 0.0265
Epoch 56/100
1068/1068 - 1s - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 57/100
1068/1068 - 1s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0264 - val_mse: 0.0264
Epoch 58/100
1068/1068 - 1s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0295 - val_mse: 0.0295
Epoch 59/100
1068/1068 - 1s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0264 - val_mse: 0.0264
Epoch 60/100
1068/1068 - 1s - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 61/100
1068/1068 - 1s - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 62/100
1068/1068 - 1s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0273 - val_mse: 0.0273
saving model CNNxySTOCHASTIC0
model 1/120
time elapsed:
00:00:44.51
estimated time left:
01:28:16.12 


STOCHASTIC run: 1
Train on 988 samples, validate on 247 samples
Epoch 1/100
988/988 - 2s - loss: 0.2498 - mse: 0.2498 - val_loss: 0.2068 - val_mse: 0.2068
Epoch 2/100
988/988 - 1s - loss: 0.1639 - mse: 0.1639 - val_loss: 0.1313 - val_mse: 0.1313
Epoch 3/100
988/988 - 1s - loss: 0.1179 - mse: 0.1179 - val_loss: 0.1114 - val_mse: 0.1114
Epoch 4/100
988/988 - 1s - loss: 0.0957 - mse: 0.0957 - val_loss: 0.0834 - val_mse: 0.0834
Epoch 5/100
988/988 - 1s - loss: 0.0697 - mse: 0.0697 - val_loss: 0.0656 - val_mse: 0.0656
Epoch 6/100
988/988 - 1s - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0546 - val_mse: 0.0546
Epoch 7/100
988/988 - 1s - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0470 - val_mse: 0.0470
Epoch 8/100
988/988 - 1s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0434 - val_mse: 0.0434
Epoch 9/100
988/988 - 1s - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0375 - val_mse: 0.0375
Epoch 10/100
988/988 - 1s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 11/100
988/988 - 1s - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0312 - val_mse: 0.0312
Epoch 12/100
988/988 - 1s - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0275 - val_mse: 0.0275
Epoch 13/100
988/988 - 1s - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 14/100
988/988 - 1s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0231 - val_mse: 0.0231
Epoch 15/100
988/988 - 1s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0225 - val_mse: 0.0225
Epoch 16/100
988/988 - 1s - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 17/100
988/988 - 1s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 18/100
988/988 - 1s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0195 - val_mse: 0.0195
Epoch 19/100
988/988 - 1s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0186 - val_mse: 0.0186
Epoch 20/100
988/988 - 1s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 21/100
988/988 - 1s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 22/100
988/988 - 1s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 23/100
988/988 - 1s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0162 - val_mse: 0.0162
Epoch 24/100
988/988 - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0155 - val_mse: 0.0155
Epoch 25/100
988/988 - 1s - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 26/100
988/988 - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0157 - val_mse: 0.0157
Epoch 27/100
988/988 - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 28/100
988/988 - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 29/100
988/988 - 1s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0150 - val_mse: 0.0150
Epoch 30/100
988/988 - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0160 - val_mse: 0.0160
Epoch 31/100
988/988 - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0143 - val_mse: 0.0143
Epoch 32/100
988/988 - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 33/100
988/988 - 1s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0150 - val_mse: 0.0150
Epoch 34/100
988/988 - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0143 - val_mse: 0.0143
Epoch 35/100
988/988 - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0143 - val_mse: 0.0143
Epoch 36/100
988/988 - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 37/100
988/988 - 1s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 38/100
988/988 - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 39/100
988/988 - 1s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 40/100
988/988 - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 41/100
988/988 - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0135 - val_mse: 0.0135
Epoch 42/100
988/988 - 1s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 43/100
988/988 - 1s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0142 - val_mse: 0.0142
Epoch 44/100
988/988 - 1s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 45/100
988/988 - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 46/100
988/988 - 1s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0136 - val_mse: 0.0136
Epoch 47/100
988/988 - 1s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0144 - val_mse: 0.0144
Epoch 48/100
988/988 - 1s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 49/100
988/988 - 1s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0144 - val_mse: 0.0144
Epoch 50/100
988/988 - 1s - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 51/100
988/988 - 1s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0142 - val_mse: 0.0142
saving model CNNxySTOCHASTIC1
model 2/120
time elapsed:
00:01:15.72
estimated time left:
01:14:27.52 


STOCHASTIC run: 2
Train on 908 samples, validate on 227 samples
Epoch 1/100
908/908 - 2s - loss: 1.1611 - mse: 1.1611 - val_loss: 0.3596 - val_mse: 0.3596
Epoch 2/100
908/908 - 1s - loss: 0.2732 - mse: 0.2732 - val_loss: 0.2136 - val_mse: 0.2136
Epoch 3/100
908/908 - 1s - loss: 0.1994 - mse: 0.1994 - val_loss: 0.1925 - val_mse: 0.1925
Epoch 4/100
908/908 - 1s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1923 - val_mse: 0.1923
Epoch 5/100
908/908 - 1s - loss: 0.1906 - mse: 0.1906 - val_loss: 0.1927 - val_mse: 0.1927
Epoch 6/100
908/908 - 1s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 7/100
908/908 - 1s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 8/100
908/908 - 1s - loss: 0.1907 - mse: 0.1907 - val_loss: 0.1927 - val_mse: 0.1927
Epoch 9/100
908/908 - 1s - loss: 0.1907 - mse: 0.1907 - val_loss: 0.1918 - val_mse: 0.1918
Epoch 10/100
908/908 - 1s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 11/100
908/908 - 1s - loss: 0.1901 - mse: 0.1901 - val_loss: 0.1920 - val_mse: 0.1920
Epoch 12/100
908/908 - 1s - loss: 0.1901 - mse: 0.1901 - val_loss: 0.1918 - val_mse: 0.1918
Epoch 13/100
908/908 - 1s - loss: 0.1908 - mse: 0.1908 - val_loss: 0.1921 - val_mse: 0.1921
Epoch 14/100
908/908 - 1s - loss: 0.1909 - mse: 0.1909 - val_loss: 0.1918 - val_mse: 0.1918
Epoch 15/100
908/908 - 1s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1922 - val_mse: 0.1922
Epoch 16/100
908/908 - 1s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1914 - val_mse: 0.1914
Epoch 17/100
908/908 - 1s - loss: 0.1898 - mse: 0.1898 - val_loss: 0.1912 - val_mse: 0.1912
Epoch 18/100
908/908 - 1s - loss: 0.1896 - mse: 0.1896 - val_loss: 0.1886 - val_mse: 0.1886
Epoch 19/100
908/908 - 1s - loss: 0.1847 - mse: 0.1847 - val_loss: 0.1806 - val_mse: 0.1806
Epoch 20/100
908/908 - 1s - loss: 0.1778 - mse: 0.1778 - val_loss: 0.1747 - val_mse: 0.1747
Epoch 21/100
908/908 - 1s - loss: 0.1724 - mse: 0.1724 - val_loss: 0.1654 - val_mse: 0.1654
Epoch 22/100
908/908 - 1s - loss: 0.1610 - mse: 0.1610 - val_loss: 0.1491 - val_mse: 0.1491
Epoch 23/100
908/908 - 1s - loss: 0.1474 - mse: 0.1474 - val_loss: 0.1343 - val_mse: 0.1343
Epoch 24/100
908/908 - 1s - loss: 0.1306 - mse: 0.1306 - val_loss: 0.1164 - val_mse: 0.1164
Epoch 25/100
908/908 - 1s - loss: 0.1168 - mse: 0.1168 - val_loss: 0.1051 - val_mse: 0.1051
Epoch 26/100
908/908 - 1s - loss: 0.1029 - mse: 0.1029 - val_loss: 0.0955 - val_mse: 0.0955
Epoch 27/100
908/908 - 1s - loss: 0.0932 - mse: 0.0932 - val_loss: 0.0876 - val_mse: 0.0876
Epoch 28/100
908/908 - 1s - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0742 - val_mse: 0.0742
Epoch 29/100
908/908 - 1s - loss: 0.0685 - mse: 0.0685 - val_loss: 0.0648 - val_mse: 0.0648
Epoch 30/100
908/908 - 1s - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0564 - val_mse: 0.0564
Epoch 31/100
908/908 - 1s - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0495 - val_mse: 0.0495
Epoch 32/100
908/908 - 1s - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0425 - val_mse: 0.0425
Epoch 33/100
908/908 - 1s - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0383 - val_mse: 0.0383
Epoch 34/100
908/908 - 1s - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0363 - val_mse: 0.0363
Epoch 35/100
908/908 - 1s - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0310 - val_mse: 0.0310
Epoch 36/100
908/908 - 1s - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0302 - val_mse: 0.0302
Epoch 37/100
908/908 - 1s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 38/100
908/908 - 1s - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 39/100
908/908 - 1s - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0270 - val_mse: 0.0270
Epoch 40/100
908/908 - 1s - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0245 - val_mse: 0.0245
Epoch 41/100
908/908 - 1s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0233 - val_mse: 0.0233
Epoch 42/100
908/908 - 1s - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0229 - val_mse: 0.0229
Epoch 43/100
908/908 - 1s - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0226 - val_mse: 0.0226
Epoch 44/100
908/908 - 1s - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 45/100
908/908 - 1s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0195 - val_mse: 0.0195
Epoch 46/100
908/908 - 1s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 47/100
908/908 - 1s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 48/100
908/908 - 1s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 49/100
908/908 - 1s - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 50/100
908/908 - 1s - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0180 - val_mse: 0.0180
Epoch 51/100
908/908 - 1s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0206 - val_mse: 0.0206
Epoch 52/100
908/908 - 1s - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 53/100
908/908 - 1s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0167 - val_mse: 0.0167
Epoch 54/100
908/908 - 1s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0165 - val_mse: 0.0165
Epoch 55/100
908/908 - 1s - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0167 - val_mse: 0.0167
Epoch 56/100
908/908 - 1s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0159 - val_mse: 0.0159
Epoch 57/100
908/908 - 1s - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0166 - val_mse: 0.0166
Epoch 58/100
908/908 - 1s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0166 - val_mse: 0.0166
Epoch 59/100
908/908 - 1s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0154 - val_mse: 0.0154
Epoch 60/100
908/908 - 1s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0163 - val_mse: 0.0163
Epoch 61/100
908/908 - 1s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 62/100
908/908 - 1s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0165 - val_mse: 0.0165
Epoch 63/100
908/908 - 1s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 64/100
908/908 - 1s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0164 - val_mse: 0.0164
Epoch 65/100
908/908 - 1s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 66/100
908/908 - 1s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0156 - val_mse: 0.0156
Epoch 67/100
908/908 - 1s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 68/100
908/908 - 1s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 69/100
908/908 - 1s - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0139 - val_mse: 0.0139
Epoch 70/100
908/908 - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0153 - val_mse: 0.0153
Epoch 71/100
908/908 - 1s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0154 - val_mse: 0.0154
Epoch 72/100
908/908 - 1s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0144 - val_mse: 0.0144
Epoch 73/100
908/908 - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 74/100
908/908 - 1s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 75/100
908/908 - 1s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0139 - val_mse: 0.0139
Epoch 76/100
908/908 - 1s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 77/100
908/908 - 1s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0139 - val_mse: 0.0139
Epoch 78/100
908/908 - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 79/100
908/908 - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 80/100
908/908 - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 81/100
908/908 - 1s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 82/100
908/908 - 1s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 83/100
908/908 - 1s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0134 - val_mse: 0.0134
Epoch 84/100
908/908 - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0142 - val_mse: 0.0142
Epoch 85/100
908/908 - 1s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 86/100
908/908 - 1s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0143 - val_mse: 0.0143
Epoch 87/100
908/908 - 1s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 88/100
908/908 - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0138 - val_mse: 0.0138
Epoch 89/100
908/908 - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0135 - val_mse: 0.0135
Epoch 90/100
908/908 - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0149 - val_mse: 0.0149
Epoch 91/100
908/908 - 1s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0140 - val_mse: 0.0140
Epoch 92/100
908/908 - 1s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0139 - val_mse: 0.0139
Epoch 93/100
908/908 - 1s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0134 - val_mse: 0.0134
saving model CNNxySTOCHASTIC2
model 3/120
time elapsed:
00:02:07.68
estimated time left:
01:22:59.58 


STOCHASTIC run: 3
Train on 828 samples, validate on 207 samples
Epoch 1/100
828/828 - 2s - loss: 0.2869 - mse: 0.2869 - val_loss: 0.2088 - val_mse: 0.2088
Epoch 2/100
828/828 - 0s - loss: 0.1830 - mse: 0.1830 - val_loss: 0.1552 - val_mse: 0.1552
Epoch 3/100
828/828 - 0s - loss: 0.1317 - mse: 0.1317 - val_loss: 0.1218 - val_mse: 0.1218
Epoch 4/100
828/828 - 0s - loss: 0.1157 - mse: 0.1157 - val_loss: 0.1073 - val_mse: 0.1073
Epoch 5/100
828/828 - 0s - loss: 0.1052 - mse: 0.1052 - val_loss: 0.0988 - val_mse: 0.0988
Epoch 6/100
828/828 - 0s - loss: 0.0919 - mse: 0.0919 - val_loss: 0.0832 - val_mse: 0.0832
Epoch 7/100
828/828 - 0s - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0609 - val_mse: 0.0609
Epoch 8/100
828/828 - 0s - loss: 0.0543 - mse: 0.0543 - val_loss: 0.0496 - val_mse: 0.0496
Epoch 9/100
828/828 - 0s - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0467 - val_mse: 0.0467
Epoch 10/100
828/828 - 0s - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0450 - val_mse: 0.0450
Epoch 11/100
828/828 - 0s - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0415 - val_mse: 0.0415
Epoch 12/100
828/828 - 0s - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0403 - val_mse: 0.0403
Epoch 13/100
828/828 - 0s - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0360 - val_mse: 0.0360
Epoch 14/100
828/828 - 0s - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 15/100
828/828 - 0s - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0281 - val_mse: 0.0281
Epoch 16/100
828/828 - 0s - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0257 - val_mse: 0.0257
Epoch 17/100
828/828 - 0s - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0232 - val_mse: 0.0232
Epoch 18/100
828/828 - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0199 - val_mse: 0.0199
Epoch 19/100
828/828 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0199 - val_mse: 0.0199
Epoch 20/100
828/828 - 0s - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 21/100
828/828 - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 22/100
828/828 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0165 - val_mse: 0.0165
Epoch 23/100
828/828 - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0169 - val_mse: 0.0169
Epoch 24/100
828/828 - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0146 - val_mse: 0.0146
Epoch 25/100
828/828 - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 26/100
828/828 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 27/100
828/828 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0144 - val_mse: 0.0144
Epoch 28/100
828/828 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0137 - val_mse: 0.0137
Epoch 29/100
828/828 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 30/100
828/828 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 31/100
828/828 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0128 - val_mse: 0.0128
Epoch 32/100
828/828 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 33/100
828/828 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0135 - val_mse: 0.0135
Epoch 34/100
828/828 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0128 - val_mse: 0.0128
Epoch 35/100
828/828 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0130 - val_mse: 0.0130
Epoch 36/100
828/828 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0131 - val_mse: 0.0131
Epoch 37/100
828/828 - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0127 - val_mse: 0.0127
Epoch 38/100
828/828 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0124 - val_mse: 0.0124
Epoch 39/100
828/828 - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0128 - val_mse: 0.0128
Epoch 40/100
828/828 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0130 - val_mse: 0.0130
Epoch 41/100
828/828 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0126 - val_mse: 0.0126
Epoch 42/100
828/828 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0132 - val_mse: 0.0132
Epoch 43/100
828/828 - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0129 - val_mse: 0.0129
Epoch 44/100
828/828 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0132 - val_mse: 0.0132
Epoch 45/100
828/828 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0129 - val_mse: 0.0129
Epoch 46/100
828/828 - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0126 - val_mse: 0.0126
Epoch 47/100
828/828 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0132 - val_mse: 0.0132
Epoch 48/100
828/828 - 0s - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0127 - val_mse: 0.0127
saving model CNNxySTOCHASTIC3
model 4/120
time elapsed:
00:02:32.62
estimated time left:
01:13:45.99 


STOCHASTIC run: 4
Train on 748 samples, validate on 187 samples
Epoch 1/100
748/748 - 2s - loss: 2.4351 - mse: 2.4351 - val_loss: 1.2599 - val_mse: 1.2599
Epoch 2/100
748/748 - 0s - loss: 0.9419 - mse: 0.9419 - val_loss: 0.6839 - val_mse: 0.6839
Epoch 3/100
748/748 - 0s - loss: 0.5468 - mse: 0.5468 - val_loss: 0.4270 - val_mse: 0.4270
Epoch 4/100
748/748 - 0s - loss: 0.3549 - mse: 0.3549 - val_loss: 0.2934 - val_mse: 0.2934
Epoch 5/100
748/748 - 0s - loss: 0.2590 - mse: 0.2590 - val_loss: 0.2344 - val_mse: 0.2344
Epoch 6/100
748/748 - 0s - loss: 0.2181 - mse: 0.2181 - val_loss: 0.2080 - val_mse: 0.2080
Epoch 7/100
748/748 - 0s - loss: 0.2007 - mse: 0.2007 - val_loss: 0.1971 - val_mse: 0.1971
Epoch 8/100
748/748 - 0s - loss: 0.1942 - mse: 0.1942 - val_loss: 0.1922 - val_mse: 0.1922
Epoch 9/100
748/748 - 0s - loss: 0.1913 - mse: 0.1913 - val_loss: 0.1908 - val_mse: 0.1908
Epoch 10/100
748/748 - 0s - loss: 0.1904 - mse: 0.1904 - val_loss: 0.1904 - val_mse: 0.1904
Epoch 11/100
748/748 - 0s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1902 - val_mse: 0.1902
Epoch 12/100
748/748 - 0s - loss: 0.1901 - mse: 0.1901 - val_loss: 0.1901 - val_mse: 0.1901
Epoch 13/100
748/748 - 0s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1899 - val_mse: 0.1899
Epoch 14/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1902 - val_mse: 0.1902
Epoch 15/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1901 - val_mse: 0.1901
Epoch 16/100
748/748 - 0s - loss: 0.1905 - mse: 0.1905 - val_loss: 0.1900 - val_mse: 0.1900
Epoch 17/100
748/748 - 0s - loss: 0.1908 - mse: 0.1908 - val_loss: 0.1905 - val_mse: 0.1905
Epoch 18/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1901 - val_mse: 0.1901
Epoch 19/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1899 - val_mse: 0.1899
Epoch 20/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1901 - val_mse: 0.1901
Epoch 21/100
748/748 - 0s - loss: 0.1903 - mse: 0.1903 - val_loss: 0.1903 - val_mse: 0.1903
Epoch 22/100
748/748 - 0s - loss: 0.1909 - mse: 0.1909 - val_loss: 0.1899 - val_mse: 0.1899
Epoch 23/100
748/748 - 0s - loss: 0.1902 - mse: 0.1902 - val_loss: 0.1900 - val_mse: 0.1900
saving model CNNxySTOCHASTIC4
model 5/120
time elapsed:
00:02:44.60
estimated time left:
01:03:05.75 


STOCHASTIC run: 5
Train on 668 samples, validate on 167 samples
Epoch 1/100
668/668 - 1s - loss: 0.1927 - mse: 0.1927 - val_loss: 0.1739 - val_mse: 0.1739
Epoch 2/100
668/668 - 0s - loss: 0.1580 - mse: 0.1580 - val_loss: 0.1343 - val_mse: 0.1343
Epoch 3/100
668/668 - 0s - loss: 0.1248 - mse: 0.1248 - val_loss: 0.1287 - val_mse: 0.1287
Epoch 4/100
668/668 - 0s - loss: 0.1181 - mse: 0.1181 - val_loss: 0.1231 - val_mse: 0.1231
Epoch 5/100
668/668 - 0s - loss: 0.1086 - mse: 0.1086 - val_loss: 0.1097 - val_mse: 0.1097
Epoch 6/100
668/668 - 0s - loss: 0.0907 - mse: 0.0907 - val_loss: 0.0745 - val_mse: 0.0745
Epoch 7/100
668/668 - 0s - loss: 0.0648 - mse: 0.0648 - val_loss: 0.0571 - val_mse: 0.0571
Epoch 8/100
668/668 - 0s - loss: 0.0529 - mse: 0.0529 - val_loss: 0.0481 - val_mse: 0.0481
Epoch 9/100
668/668 - 0s - loss: 0.0481 - mse: 0.0481 - val_loss: 0.0489 - val_mse: 0.0489
Epoch 10/100
668/668 - 0s - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0418 - val_mse: 0.0418
Epoch 11/100
668/668 - 0s - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0425 - val_mse: 0.0425
Epoch 12/100
668/668 - 0s - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0377 - val_mse: 0.0377
Epoch 13/100
668/668 - 0s - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0361 - val_mse: 0.0361
Epoch 14/100
668/668 - 0s - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0339 - val_mse: 0.0339
Epoch 15/100
668/668 - 0s - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0312 - val_mse: 0.0312
Epoch 16/100
668/668 - 0s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0300 - val_mse: 0.0300
Epoch 17/100
668/668 - 0s - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0291 - val_mse: 0.0291
Epoch 18/100
668/668 - 0s - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 19/100
668/668 - 0s - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 20/100
668/668 - 0s - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 21/100
668/668 - 0s - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 22/100
668/668 - 0s - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0212 - val_mse: 0.0212
Epoch 23/100
668/668 - 0s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0207 - val_mse: 0.0207
Epoch 24/100
668/668 - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 25/100
668/668 - 0s - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 26/100
668/668 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 27/100
668/668 - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 28/100
668/668 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0167 - val_mse: 0.0167
Epoch 29/100
668/668 - 0s - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0161 - val_mse: 0.0161
Epoch 30/100
668/668 - 0s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 31/100
668/668 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0155 - val_mse: 0.0155
Epoch 32/100
668/668 - 0s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0166 - val_mse: 0.0166
Epoch 33/100
668/668 - 0s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0157 - val_mse: 0.0157
Epoch 34/100
668/668 - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0152 - val_mse: 0.0152
Epoch 35/100
668/668 - 0s - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0157 - val_mse: 0.0157
Epoch 36/100
668/668 - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0155 - val_mse: 0.0155
Epoch 37/100
668/668 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0149 - val_mse: 0.0149
Epoch 38/100
668/668 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 39/100
668/668 - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0150 - val_mse: 0.0150
Epoch 40/100
668/668 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 41/100
668/668 - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0147 - val_mse: 0.0147
Epoch 42/100
668/668 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0141 - val_mse: 0.0141
Epoch 43/100
668/668 - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0149 - val_mse: 0.0149
Epoch 44/100
668/668 - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 45/100
668/668 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0145 - val_mse: 0.0145
Epoch 46/100
668/668 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 47/100
668/668 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0148 - val_mse: 0.0148
Epoch 48/100
668/668 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0151 - val_mse: 0.0151
Epoch 49/100
668/668 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0153 - val_mse: 0.0153
Epoch 50/100
668/668 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0156 - val_mse: 0.0156
Epoch 51/100
668/668 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0149 - val_mse: 0.0149
Epoch 52/100
668/668 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0149 - val_mse: 0.0149
saving model CNNxySTOCHASTIC5
model 6/120
time elapsed:
00:03:06.58
estimated time left:
00:59:05.06 


STOCHASTIC run: 6
Train on 588 samples, validate on 147 samples
Epoch 1/100
588/588 - 1s - loss: 0.6295 - mse: 0.6295 - val_loss: 0.2397 - val_mse: 0.2397
Epoch 2/100
588/588 - 0s - loss: 0.2037 - mse: 0.2037 - val_loss: 0.1869 - val_mse: 0.1869
Epoch 3/100
588/588 - 0s - loss: 0.1868 - mse: 0.1868 - val_loss: 0.1904 - val_mse: 0.1904
Epoch 4/100
588/588 - 0s - loss: 0.1822 - mse: 0.1822 - val_loss: 0.1798 - val_mse: 0.1798
Epoch 5/100
588/588 - 0s - loss: 0.1683 - mse: 0.1683 - val_loss: 0.1602 - val_mse: 0.1602
Epoch 6/100
588/588 - 0s - loss: 0.1496 - mse: 0.1496 - val_loss: 0.1457 - val_mse: 0.1457
Epoch 7/100
588/588 - 0s - loss: 0.1399 - mse: 0.1399 - val_loss: 0.1381 - val_mse: 0.1381
Epoch 8/100
588/588 - 0s - loss: 0.1343 - mse: 0.1343 - val_loss: 0.1326 - val_mse: 0.1326
Epoch 9/100
588/588 - 0s - loss: 0.1292 - mse: 0.1292 - val_loss: 0.1325 - val_mse: 0.1325
Epoch 10/100
588/588 - 0s - loss: 0.1301 - mse: 0.1301 - val_loss: 0.1313 - val_mse: 0.1313
Epoch 11/100
588/588 - 0s - loss: 0.1252 - mse: 0.1252 - val_loss: 0.1295 - val_mse: 0.1295
Epoch 12/100
588/588 - 0s - loss: 0.1217 - mse: 0.1217 - val_loss: 0.1236 - val_mse: 0.1236
Epoch 13/100
588/588 - 0s - loss: 0.1170 - mse: 0.1170 - val_loss: 0.1211 - val_mse: 0.1211
Epoch 14/100
588/588 - 0s - loss: 0.1122 - mse: 0.1122 - val_loss: 0.1164 - val_mse: 0.1164
Epoch 15/100
588/588 - 0s - loss: 0.1066 - mse: 0.1066 - val_loss: 0.1137 - val_mse: 0.1137
Epoch 16/100
588/588 - 0s - loss: 0.1007 - mse: 0.1007 - val_loss: 0.1060 - val_mse: 0.1060
Epoch 17/100
588/588 - 0s - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0946 - val_mse: 0.0946
Epoch 18/100
588/588 - 0s - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0842 - val_mse: 0.0842
Epoch 19/100
588/588 - 0s - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0771 - val_mse: 0.0771
Epoch 20/100
588/588 - 0s - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0691 - val_mse: 0.0691
Epoch 21/100
588/588 - 0s - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0626 - val_mse: 0.0626
Epoch 22/100
588/588 - 0s - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0617 - val_mse: 0.0617
Epoch 23/100
588/588 - 0s - loss: 0.0486 - mse: 0.0486 - val_loss: 0.0566 - val_mse: 0.0566
Epoch 24/100
588/588 - 0s - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0523 - val_mse: 0.0523
Epoch 25/100
588/588 - 0s - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0531 - val_mse: 0.0531
Epoch 26/100
588/588 - 0s - loss: 0.0395 - mse: 0.0395 - val_loss: 0.0570 - val_mse: 0.0570
Epoch 27/100
588/588 - 0s - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0464 - val_mse: 0.0464
Epoch 28/100
588/588 - 0s - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0432 - val_mse: 0.0432
Epoch 29/100
588/588 - 0s - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0425 - val_mse: 0.0425
Epoch 30/100
588/588 - 0s - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0409 - val_mse: 0.0409
Epoch 31/100
588/588 - 0s - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0398 - val_mse: 0.0398
Epoch 32/100
588/588 - 0s - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0361 - val_mse: 0.0361
Epoch 33/100
588/588 - 0s - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0433 - val_mse: 0.0433
Epoch 34/100
588/588 - 0s - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0372 - val_mse: 0.0372
Epoch 35/100
588/588 - 0s - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0337 - val_mse: 0.0337
Epoch 36/100
588/588 - 0s - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0334 - val_mse: 0.0334
Epoch 37/100
588/588 - 0s - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0327 - val_mse: 0.0327
Epoch 38/100
588/588 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 39/100
588/588 - 0s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0290 - val_mse: 0.0290
Epoch 40/100
588/588 - 0s - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0294 - val_mse: 0.0294
Epoch 41/100
588/588 - 0s - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0282 - val_mse: 0.0282
Epoch 42/100
588/588 - 0s - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 43/100
588/588 - 0s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 44/100
588/588 - 0s - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 45/100
588/588 - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0252 - val_mse: 0.0252
Epoch 46/100
588/588 - 0s - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0279 - val_mse: 0.0279
Epoch 47/100
588/588 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0238 - val_mse: 0.0238
Epoch 48/100
588/588 - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0247 - val_mse: 0.0247
Epoch 49/100
588/588 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 50/100
588/588 - 0s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0242 - val_mse: 0.0242
Epoch 51/100
588/588 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0234 - val_mse: 0.0234
Epoch 52/100
588/588 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 53/100
588/588 - 0s - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0235 - val_mse: 0.0235
Epoch 54/100
588/588 - 0s - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 55/100
588/588 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0216 - val_mse: 0.0216
Epoch 56/100
588/588 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 57/100
588/588 - 0s - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0213 - val_mse: 0.0213
Epoch 58/100
588/588 - 0s - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 59/100
588/588 - 0s - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 60/100
588/588 - 0s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 61/100
588/588 - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0194 - val_mse: 0.0194
Epoch 62/100
588/588 - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0219 - val_mse: 0.0219
Epoch 63/100
588/588 - 0s - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 64/100
588/588 - 0s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0195 - val_mse: 0.0195
Epoch 65/100
588/588 - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0198 - val_mse: 0.0198
Epoch 66/100
588/588 - 0s - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 67/100
588/588 - 0s - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0186 - val_mse: 0.0186
Epoch 68/100
588/588 - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0179 - val_mse: 0.0179
Epoch 69/100
588/588 - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0184 - val_mse: 0.0184
Epoch 70/100
588/588 - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0185 - val_mse: 0.0185
Epoch 71/100
588/588 - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0178 - val_mse: 0.0178
Epoch 72/100
588/588 - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0184 - val_mse: 0.0184
Epoch 73/100
588/588 - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0184 - val_mse: 0.0184
Epoch 74/100
588/588 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0178 - val_mse: 0.0178
Epoch 75/100
588/588 - 0s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 76/100
588/588 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 77/100
588/588 - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0184 - val_mse: 0.0184
Epoch 78/100
588/588 - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 79/100
588/588 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0172 - val_mse: 0.0172
Epoch 80/100
588/588 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 81/100
588/588 - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0174 - val_mse: 0.0174
Epoch 82/100
588/588 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 83/100
588/588 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 84/100
588/588 - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0174 - val_mse: 0.0174
Epoch 85/100
588/588 - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 86/100
588/588 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0170 - val_mse: 0.0170
Epoch 87/100
588/588 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 88/100
588/588 - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 89/100
588/588 - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0169 - val_mse: 0.0169
Epoch 90/100
588/588 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0177 - val_mse: 0.0177
Epoch 91/100
588/588 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 92/100
588/588 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0175 - val_mse: 0.0175
Epoch 93/100
588/588 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0183 - val_mse: 0.0183
Epoch 94/100
588/588 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0176 - val_mse: 0.0176
Epoch 95/100
588/588 - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0175 - val_mse: 0.0175
Epoch 96/100
588/588 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0172 - val_mse: 0.0172
Epoch 97/100
588/588 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0186 - val_mse: 0.0186
Epoch 98/100
588/588 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0181 - val_mse: 0.0181
Epoch 99/100
588/588 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0178 - val_mse: 0.0178
saving model CNNxySTOCHASTIC6
model 7/120
time elapsed:
00:03:42.55
estimated time left:
00:59:52.57 


STOCHASTIC run: 7
Train on 508 samples, validate on 127 samples
Epoch 1/100
508/508 - 1s - loss: 0.4927 - mse: 0.4927 - val_loss: 0.2622 - val_mse: 0.2622
Epoch 2/100
508/508 - 0s - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2131 - val_mse: 0.2131
Epoch 3/100
508/508 - 0s - loss: 0.2231 - mse: 0.2231 - val_loss: 0.2128 - val_mse: 0.2128
Epoch 4/100
508/508 - 0s - loss: 0.2069 - mse: 0.2069 - val_loss: 0.1864 - val_mse: 0.1864
Epoch 5/100
508/508 - 0s - loss: 0.1838 - mse: 0.1838 - val_loss: 0.1707 - val_mse: 0.1707
Epoch 6/100
508/508 - 0s - loss: 0.1633 - mse: 0.1633 - val_loss: 0.1434 - val_mse: 0.1434
Epoch 7/100
508/508 - 0s - loss: 0.1377 - mse: 0.1377 - val_loss: 0.1337 - val_mse: 0.1337
Epoch 8/100
508/508 - 0s - loss: 0.1274 - mse: 0.1274 - val_loss: 0.1203 - val_mse: 0.1203
Epoch 9/100
508/508 - 0s - loss: 0.1148 - mse: 0.1148 - val_loss: 0.1098 - val_mse: 0.1098
Epoch 10/100
508/508 - 0s - loss: 0.1035 - mse: 0.1035 - val_loss: 0.1016 - val_mse: 0.1016
Epoch 11/100
508/508 - 0s - loss: 0.0899 - mse: 0.0899 - val_loss: 0.0866 - val_mse: 0.0866
Epoch 12/100
508/508 - 0s - loss: 0.0762 - mse: 0.0762 - val_loss: 0.0740 - val_mse: 0.0740
Epoch 13/100
508/508 - 0s - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0624 - val_mse: 0.0624
Epoch 14/100
508/508 - 0s - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0578 - val_mse: 0.0578
Epoch 15/100
508/508 - 0s - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0518 - val_mse: 0.0518
Epoch 16/100
508/508 - 0s - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0497 - val_mse: 0.0497
Epoch 17/100
508/508 - 0s - loss: 0.0420 - mse: 0.0420 - val_loss: 0.0468 - val_mse: 0.0468
Epoch 18/100
508/508 - 0s - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0448 - val_mse: 0.0448
Epoch 19/100
508/508 - 0s - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0447 - val_mse: 0.0447
Epoch 20/100
508/508 - 0s - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0420 - val_mse: 0.0420
Epoch 21/100
508/508 - 0s - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0406 - val_mse: 0.0406
Epoch 22/100
508/508 - 0s - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0390 - val_mse: 0.0390
Epoch 23/100
508/508 - 0s - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0380 - val_mse: 0.0380
Epoch 24/100
508/508 - 0s - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0371 - val_mse: 0.0371
Epoch 25/100
508/508 - 0s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0358 - val_mse: 0.0358
Epoch 26/100
508/508 - 0s - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0343 - val_mse: 0.0343
Epoch 27/100
508/508 - 0s - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0356 - val_mse: 0.0356
Epoch 28/100
508/508 - 0s - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0332 - val_mse: 0.0332
Epoch 29/100
508/508 - 0s - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0334 - val_mse: 0.0334
Epoch 30/100
508/508 - 0s - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0334 - val_mse: 0.0334
Epoch 31/100
508/508 - 0s - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0337 - val_mse: 0.0337
Epoch 32/100
508/508 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0333 - val_mse: 0.0333
Epoch 33/100
508/508 - 0s - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0335 - val_mse: 0.0335
Epoch 34/100
508/508 - 0s - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0327 - val_mse: 0.0327
Epoch 35/100
508/508 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0323 - val_mse: 0.0323
Epoch 36/100
508/508 - 0s - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0323 - val_mse: 0.0323
Epoch 37/100
508/508 - 0s - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0318 - val_mse: 0.0318
Epoch 38/100
508/508 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0315 - val_mse: 0.0315
Epoch 39/100
508/508 - 0s - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0313 - val_mse: 0.0313
Epoch 40/100
508/508 - 0s - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 41/100
508/508 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 42/100
508/508 - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0317 - val_mse: 0.0317
Epoch 43/100
508/508 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0308 - val_mse: 0.0308
Epoch 44/100
508/508 - 0s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0323 - val_mse: 0.0323
Epoch 45/100
508/508 - 0s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0301 - val_mse: 0.0301
Epoch 46/100
508/508 - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0305 - val_mse: 0.0305
Epoch 47/100
508/508 - 0s - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0295 - val_mse: 0.0295
Epoch 48/100
508/508 - 0s - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0315 - val_mse: 0.0315
Epoch 49/100
508/508 - 0s - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 50/100
508/508 - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0294 - val_mse: 0.0294
Epoch 51/100
508/508 - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0286 - val_mse: 0.0286
Epoch 52/100
508/508 - 0s - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0301 - val_mse: 0.0301
Epoch 53/100
508/508 - 0s - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0286 - val_mse: 0.0286
Epoch 54/100
508/508 - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0294 - val_mse: 0.0294
Epoch 55/100
508/508 - 0s - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0290 - val_mse: 0.0290
Epoch 56/100
508/508 - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0287 - val_mse: 0.0287
Epoch 57/100
508/508 - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0288 - val_mse: 0.0288
Epoch 58/100
508/508 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0276 - val_mse: 0.0276
Epoch 59/100
508/508 - 0s - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0281 - val_mse: 0.0281
Epoch 60/100
508/508 - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0285 - val_mse: 0.0285
Epoch 61/100
508/508 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0275 - val_mse: 0.0275
Epoch 62/100
508/508 - 0s - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0280 - val_mse: 0.0280
Epoch 63/100
508/508 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0288 - val_mse: 0.0288
Epoch 64/100
508/508 - 0s - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0274 - val_mse: 0.0274
Epoch 65/100
508/508 - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0277 - val_mse: 0.0277
Epoch 66/100
508/508 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 67/100
508/508 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0273 - val_mse: 0.0273
Epoch 68/100
508/508 - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0267 - val_mse: 0.0267
Epoch 69/100
508/508 - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0272 - val_mse: 0.0272
Epoch 70/100
508/508 - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 71/100
508/508 - 0s - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0268 - val_mse: 0.0268
Epoch 72/100
508/508 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0270 - val_mse: 0.0270
Epoch 73/100
508/508 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 74/100
508/508 - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0270 - val_mse: 0.0270
Epoch 75/100
508/508 - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0265 - val_mse: 0.0265
Epoch 76/100
508/508 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 77/100
508/508 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0266 - val_mse: 0.0266
Epoch 78/100
508/508 - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0264 - val_mse: 0.0264
Epoch 79/100
508/508 - 0s - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 80/100
508/508 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0264 - val_mse: 0.0264
Epoch 81/100
508/508 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0260 - val_mse: 0.0260
Epoch 82/100
508/508 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0259 - val_mse: 0.0259
Epoch 83/100
508/508 - 0s - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 84/100
508/508 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 85/100
508/508 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0258 - val_mse: 0.0258
Epoch 86/100
508/508 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 87/100
508/508 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0254 - val_mse: 0.0254
Epoch 88/100
508/508 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0257 - val_mse: 0.0257
Epoch 89/100
508/508 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 90/100
508/508 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0255 - val_mse: 0.0255
Epoch 91/100
508/508 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 92/100
508/508 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0255 - val_mse: 0.0255
Epoch 93/100
508/508 - 0s - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 94/100
508/508 - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0256 - val_mse: 0.0256
Epoch 95/100
508/508 - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 96/100
508/508 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 97/100
508/508 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0252 - val_mse: 0.0252
Epoch 98/100
508/508 - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0249 - val_mse: 0.0249
Epoch 99/100
508/508 - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 100/100
508/508 - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0246 - val_mse: 0.0246
saving model CNNxySTOCHASTIC7
model 8/120
time elapsed:
00:04:13.78
estimated time left:
00:59:12.92 


STOCHASTIC run: 8
Train on 428 samples, validate on 107 samples
Epoch 1/100
428/428 - 1s - loss: 0.4459 - mse: 0.4459 - val_loss: 0.2386 - val_mse: 0.2386
Epoch 2/100
428/428 - 0s - loss: 0.2031 - mse: 0.2031 - val_loss: 0.1879 - val_mse: 0.1879
Epoch 3/100
428/428 - 0s - loss: 0.1994 - mse: 0.1994 - val_loss: 0.1929 - val_mse: 0.1929
Epoch 4/100
428/428 - 0s - loss: 0.1934 - mse: 0.1934 - val_loss: 0.1804 - val_mse: 0.1804
Epoch 5/100
428/428 - 0s - loss: 0.1784 - mse: 0.1784 - val_loss: 0.1628 - val_mse: 0.1628
Epoch 6/100
428/428 - 0s - loss: 0.1564 - mse: 0.1564 - val_loss: 0.1397 - val_mse: 0.1397
Epoch 7/100
428/428 - 0s - loss: 0.1364 - mse: 0.1364 - val_loss: 0.1263 - val_mse: 0.1263
Epoch 8/100
428/428 - 0s - loss: 0.1278 - mse: 0.1278 - val_loss: 0.1197 - val_mse: 0.1197
Epoch 9/100
428/428 - 0s - loss: 0.1189 - mse: 0.1189 - val_loss: 0.1110 - val_mse: 0.1110
Epoch 10/100
428/428 - 0s - loss: 0.1114 - mse: 0.1114 - val_loss: 0.1025 - val_mse: 0.1025
Epoch 11/100
428/428 - 0s - loss: 0.1023 - mse: 0.1023 - val_loss: 0.1011 - val_mse: 0.1011
Epoch 12/100
428/428 - 0s - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0870 - val_mse: 0.0870
Epoch 13/100
428/428 - 0s - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0770 - val_mse: 0.0770
Epoch 14/100
428/428 - 0s - loss: 0.0710 - mse: 0.0710 - val_loss: 0.0676 - val_mse: 0.0676
Epoch 15/100
428/428 - 0s - loss: 0.0647 - mse: 0.0647 - val_loss: 0.0613 - val_mse: 0.0613
Epoch 16/100
428/428 - 0s - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0562 - val_mse: 0.0562
Epoch 17/100
428/428 - 0s - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0503 - val_mse: 0.0503
Epoch 18/100
428/428 - 0s - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0453 - val_mse: 0.0453
Epoch 19/100
428/428 - 0s - loss: 0.0449 - mse: 0.0449 - val_loss: 0.0466 - val_mse: 0.0466
Epoch 20/100
428/428 - 0s - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0396 - val_mse: 0.0396
Epoch 21/100
428/428 - 0s - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0391 - val_mse: 0.0391
Epoch 22/100
428/428 - 0s - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0399 - val_mse: 0.0399
Epoch 23/100
428/428 - 0s - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0342 - val_mse: 0.0342
Epoch 24/100
428/428 - 0s - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0327 - val_mse: 0.0327
Epoch 25/100
428/428 - 0s - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0306 - val_mse: 0.0306
Epoch 26/100
428/428 - 0s - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0339 - val_mse: 0.0339
Epoch 27/100
428/428 - 0s - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0319 - val_mse: 0.0319
Epoch 28/100
428/428 - 0s - loss: 0.0239 - mse: 0.0239 - val_loss: 0.0328 - val_mse: 0.0328
Epoch 29/100
428/428 - 0s - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0310 - val_mse: 0.0310
Epoch 30/100
428/428 - 0s - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0283 - val_mse: 0.0283
Epoch 31/100
428/428 - 0s - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 32/100
428/428 - 0s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0237 - val_mse: 0.0237
Epoch 33/100
428/428 - 0s - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0254 - val_mse: 0.0254
Epoch 34/100
428/428 - 0s - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0233 - val_mse: 0.0233
Epoch 35/100
428/428 - 0s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 36/100
428/428 - 0s - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 37/100
428/428 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0239 - val_mse: 0.0239
Epoch 38/100
428/428 - 0s - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0242 - val_mse: 0.0242
Epoch 39/100
428/428 - 0s - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 40/100
428/428 - 0s - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0208 - val_mse: 0.0208
Epoch 41/100
428/428 - 0s - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0203 - val_mse: 0.0203
Epoch 42/100
428/428 - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 43/100
428/428 - 0s - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0239 - val_mse: 0.0239
Epoch 44/100
428/428 - 0s - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0247 - val_mse: 0.0247
Epoch 45/100
428/428 - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0206 - val_mse: 0.0206
Epoch 46/100
428/428 - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0199 - val_mse: 0.0199
Epoch 47/100
428/428 - 0s - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0242 - val_mse: 0.0242
Epoch 48/100
428/428 - 0s - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 49/100
428/428 - 0s - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0186 - val_mse: 0.0186
Epoch 50/100
428/428 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0201 - val_mse: 0.0201
Epoch 51/100
428/428 - 0s - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0185 - val_mse: 0.0185
Epoch 52/100
428/428 - 0s - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 53/100
428/428 - 0s - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0195 - val_mse: 0.0195
Epoch 54/100
428/428 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0185 - val_mse: 0.0185
Epoch 55/100
428/428 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 56/100
428/428 - 0s - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0198 - val_mse: 0.0198
Epoch 57/100
428/428 - 0s - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0193 - val_mse: 0.0193
Epoch 58/100
428/428 - 0s - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0187 - val_mse: 0.0187
Epoch 59/100
428/428 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 60/100
428/428 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0190 - val_mse: 0.0190
Epoch 61/100
428/428 - 0s - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0206 - val_mse: 0.0206
saving model CNNxySTOCHASTIC8
model 9/120
time elapsed:
00:04:31.45
estimated time left:
00:55:47.85 


STOCHASTIC run: 9
Train on 348 samples, validate on 87 samples
Epoch 1/100
348/348 - 1s - loss: 0.4559 - mse: 0.4559 - val_loss: 0.3316 - val_mse: 0.3316
Epoch 2/100
348/348 - 0s - loss: 0.2470 - mse: 0.2470 - val_loss: 0.2246 - val_mse: 0.2246
Epoch 3/100
348/348 - 0s - loss: 0.2073 - mse: 0.2073 - val_loss: 0.1794 - val_mse: 0.1794
Epoch 4/100
348/348 - 0s - loss: 0.1966 - mse: 0.1966 - val_loss: 0.1585 - val_mse: 0.1585
Epoch 5/100
348/348 - 0s - loss: 0.1752 - mse: 0.1752 - val_loss: 0.1386 - val_mse: 0.1386
Epoch 6/100
348/348 - 0s - loss: 0.1473 - mse: 0.1473 - val_loss: 0.1298 - val_mse: 0.1298
Epoch 7/100
348/348 - 0s - loss: 0.1336 - mse: 0.1336 - val_loss: 0.1281 - val_mse: 0.1281
Epoch 8/100
348/348 - 0s - loss: 0.1246 - mse: 0.1246 - val_loss: 0.1222 - val_mse: 0.1222
Epoch 9/100
348/348 - 0s - loss: 0.1225 - mse: 0.1225 - val_loss: 0.1232 - val_mse: 0.1232
Epoch 10/100
348/348 - 0s - loss: 0.1194 - mse: 0.1194 - val_loss: 0.1123 - val_mse: 0.1123
Epoch 11/100
348/348 - 0s - loss: 0.1141 - mse: 0.1141 - val_loss: 0.1113 - val_mse: 0.1113
Epoch 12/100
348/348 - 0s - loss: 0.1081 - mse: 0.1081 - val_loss: 0.1020 - val_mse: 0.1020
Epoch 13/100
348/348 - 0s - loss: 0.1016 - mse: 0.1016 - val_loss: 0.0954 - val_mse: 0.0954
Epoch 14/100
348/348 - 0s - loss: 0.0920 - mse: 0.0920 - val_loss: 0.0930 - val_mse: 0.0930
Epoch 15/100
348/348 - 0s - loss: 0.0850 - mse: 0.0850 - val_loss: 0.0814 - val_mse: 0.0814
Epoch 16/100
348/348 - 0s - loss: 0.0749 - mse: 0.0749 - val_loss: 0.0709 - val_mse: 0.0709
Epoch 17/100
348/348 - 0s - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0638 - val_mse: 0.0638
Epoch 18/100
348/348 - 0s - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0591 - val_mse: 0.0591
Epoch 19/100
348/348 - 0s - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0529 - val_mse: 0.0529
Epoch 20/100
348/348 - 0s - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0543 - val_mse: 0.0543
Epoch 21/100
348/348 - 0s - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0448 - val_mse: 0.0448
Epoch 22/100
348/348 - 0s - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0443 - val_mse: 0.0443
Epoch 23/100
348/348 - 0s - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0408 - val_mse: 0.0408
Epoch 24/100
348/348 - 0s - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0395 - val_mse: 0.0395
Epoch 25/100
348/348 - 0s - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0390 - val_mse: 0.0390
Epoch 26/100
348/348 - 0s - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0375 - val_mse: 0.0375
Epoch 27/100
348/348 - 0s - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0374 - val_mse: 0.0374
Epoch 28/100
348/348 - 0s - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0347 - val_mse: 0.0347
Epoch 29/100
348/348 - 0s - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0352 - val_mse: 0.0352
Epoch 30/100
348/348 - 0s - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0333 - val_mse: 0.0333
Epoch 31/100
348/348 - 0s - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0334 - val_mse: 0.0334
Epoch 32/100
348/348 - 0s - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0347 - val_mse: 0.0347
Epoch 33/100
348/348 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0311 - val_mse: 0.0311
Epoch 34/100
348/348 - 0s - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0317 - val_mse: 0.0317
Epoch 35/100
348/348 - 0s - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0319 - val_mse: 0.0319
Epoch 36/100
348/348 - 0s - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0308 - val_mse: 0.0308
Epoch 37/100
348/348 - 0s - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 38/100
348/348 - 0s - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0305 - val_mse: 0.0305
Epoch 39/100
348/348 - 0s - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0287 - val_mse: 0.0287
Epoch 40/100
348/348 - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0282 - val_mse: 0.0282
Epoch 41/100
348/348 - 0s - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0297 - val_mse: 0.0297
Epoch 42/100
348/348 - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0282 - val_mse: 0.0282
Epoch 43/100
348/348 - 0s - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0273 - val_mse: 0.0273
Epoch 44/100
348/348 - 0s - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0286 - val_mse: 0.0286
Epoch 45/100
348/348 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0278 - val_mse: 0.0278
Epoch 46/100
348/348 - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0271 - val_mse: 0.0271
Epoch 47/100
348/348 - 0s - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0271 - val_mse: 0.0271
Epoch 48/100
348/348 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0270 - val_mse: 0.0270
Epoch 49/100
348/348 - 0s - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0260 - val_mse: 0.0260
Epoch 50/100
348/348 - 0s - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0259 - val_mse: 0.0259
Epoch 51/100
348/348 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0274 - val_mse: 0.0274
Epoch 52/100
348/348 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0254 - val_mse: 0.0254
Epoch 53/100
348/348 - 0s - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 54/100
348/348 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 55/100
348/348 - 0s - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 56/100
348/348 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 57/100
348/348 - 0s - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 58/100
348/348 - 0s - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0247 - val_mse: 0.0247
Epoch 59/100
348/348 - 0s - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 60/100
348/348 - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0248 - val_mse: 0.0248
Epoch 61/100
348/348 - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0240 - val_mse: 0.0240
Epoch 62/100
348/348 - 0s - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0243 - val_mse: 0.0243
Epoch 63/100
348/348 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0240 - val_mse: 0.0240
Epoch 64/100
348/348 - 0s - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0241 - val_mse: 0.0241
Epoch 65/100
348/348 - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0236 - val_mse: 0.0236
Epoch 66/100
348/348 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0233 - val_mse: 0.0233
Epoch 67/100
348/348 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0234 - val_mse: 0.0234
Epoch 68/100
348/348 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0239 - val_mse: 0.0239
Epoch 69/100
348/348 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0229 - val_mse: 0.0229
Epoch 70/100
348/348 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0230 - val_mse: 0.0230
Epoch 71/100
348/348 - 0s - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0230 - val_mse: 0.0230
Epoch 72/100
348/348 - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0224 - val_mse: 0.0224
Epoch 73/100
348/348 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0227 - val_mse: 0.0227
Epoch 74/100
348/348 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0234 - val_mse: 0.0234
Epoch 75/100
348/348 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0228 - val_mse: 0.0228
Epoch 76/100
348/348 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0224 - val_mse: 0.0224
Epoch 77/100
348/348 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 78/100
348/348 - 0s - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0231 - val_mse: 0.0231
Epoch 79/100
348/348 - 0s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0222 - val_mse: 0.0222
Epoch 80/100
348/348 - 0s - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 81/100
348/348 - 0s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0221 - val_mse: 0.0221
Epoch 82/100
348/348 - 0s - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 83/100
348/348 - 0s - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 84/100
348/348 - 0s - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 85/100
348/348 - 0s - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 86/100
348/348 - 0s - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 87/100
348/348 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0215 - val_mse: 0.0215
Epoch 88/100
348/348 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 89/100
348/348 - 0s - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0216 - val_mse: 0.0216
Epoch 90/100
348/348 - 0s - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 91/100
348/348 - 0s - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0219 - val_mse: 0.0219
Epoch 92/100
348/348 - 0s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 93/100
348/348 - 0s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0217 - val_mse: 0.0217
Epoch 94/100
348/348 - 0s - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0219 - val_mse: 0.0219
Epoch 95/100
348/348 - 0s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 96/100
348/348 - 0s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0219 - val_mse: 0.0219
Epoch 97/100
348/348 - 0s - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0214 - val_mse: 0.0214
Epoch 98/100
348/348 - 0s - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0221 - val_mse: 0.0221
Epoch 99/100
348/348 - 0s - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 100/100
348/348 - 0s - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0220 - val_mse: 0.0220
saving model CNNxySTOCHASTIC9
model 10/120
time elapsed:
00:04:53.89
estimated time left:
00:53:52.80 


STOCHASTIC run: 10
Train on 268 samples, validate on 67 samples
Epoch 1/100
268/268 - 1s - loss: 0.4984 - mse: 0.4984 - val_loss: 0.2883 - val_mse: 0.2883
Epoch 2/100
268/268 - 0s - loss: 0.2340 - mse: 0.2340 - val_loss: 0.2127 - val_mse: 0.2127
Epoch 3/100
268/268 - 0s - loss: 0.2265 - mse: 0.2265 - val_loss: 0.2398 - val_mse: 0.2398
Epoch 4/100
268/268 - 0s - loss: 0.2339 - mse: 0.2339 - val_loss: 0.2177 - val_mse: 0.2177
Epoch 5/100
268/268 - 0s - loss: 0.2045 - mse: 0.2045 - val_loss: 0.1897 - val_mse: 0.1897
Epoch 6/100
268/268 - 0s - loss: 0.1849 - mse: 0.1849 - val_loss: 0.1811 - val_mse: 0.1811
Epoch 7/100
268/268 - 0s - loss: 0.1800 - mse: 0.1800 - val_loss: 0.1690 - val_mse: 0.1690
Epoch 8/100
268/268 - 0s - loss: 0.1680 - mse: 0.1680 - val_loss: 0.1574 - val_mse: 0.1574
Epoch 9/100
268/268 - 0s - loss: 0.1551 - mse: 0.1551 - val_loss: 0.1443 - val_mse: 0.1443
Epoch 10/100
268/268 - 0s - loss: 0.1435 - mse: 0.1435 - val_loss: 0.1342 - val_mse: 0.1342
Epoch 11/100
268/268 - 0s - loss: 0.1338 - mse: 0.1338 - val_loss: 0.1234 - val_mse: 0.1234
Epoch 12/100
268/268 - 0s - loss: 0.1251 - mse: 0.1251 - val_loss: 0.1162 - val_mse: 0.1162
Epoch 13/100
268/268 - 0s - loss: 0.1176 - mse: 0.1176 - val_loss: 0.1070 - val_mse: 0.1070
Epoch 14/100
268/268 - 0s - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0996 - val_mse: 0.0996
Epoch 15/100
268/268 - 0s - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0925 - val_mse: 0.0925
Epoch 16/100
268/268 - 0s - loss: 0.0934 - mse: 0.0934 - val_loss: 0.0843 - val_mse: 0.0843
Epoch 17/100
268/268 - 0s - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0719 - val_mse: 0.0719
Epoch 18/100
268/268 - 0s - loss: 0.0690 - mse: 0.0690 - val_loss: 0.0669 - val_mse: 0.0669
Epoch 19/100
268/268 - 0s - loss: 0.0644 - mse: 0.0644 - val_loss: 0.0624 - val_mse: 0.0624
Epoch 20/100
268/268 - 0s - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0559 - val_mse: 0.0559
Epoch 21/100
268/268 - 0s - loss: 0.0533 - mse: 0.0533 - val_loss: 0.0539 - val_mse: 0.0539
Epoch 22/100
268/268 - 0s - loss: 0.0507 - mse: 0.0507 - val_loss: 0.0538 - val_mse: 0.0538
Epoch 23/100
268/268 - 0s - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0545 - val_mse: 0.0545
Epoch 24/100
268/268 - 0s - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0525 - val_mse: 0.0525
Epoch 25/100
268/268 - 0s - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0493 - val_mse: 0.0493
Epoch 26/100
268/268 - 0s - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0478 - val_mse: 0.0478
Epoch 27/100
268/268 - 0s - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0476 - val_mse: 0.0476
Epoch 28/100
268/268 - 0s - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0467 - val_mse: 0.0467
Epoch 29/100
268/268 - 0s - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0460 - val_mse: 0.0460
Epoch 30/100
268/268 - 0s - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0432 - val_mse: 0.0432
Epoch 31/100
268/268 - 0s - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0412 - val_mse: 0.0412
Epoch 32/100
268/268 - 0s - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0427 - val_mse: 0.0427
Epoch 33/100
268/268 - 0s - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0434 - val_mse: 0.0434
Epoch 34/100
268/268 - 0s - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0415 - val_mse: 0.0415
Epoch 35/100
268/268 - 0s - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0382 - val_mse: 0.0382
Epoch 36/100
268/268 - 0s - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0406 - val_mse: 0.0406
Epoch 37/100
268/268 - 0s - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0374 - val_mse: 0.0374
Epoch 38/100
268/268 - 0s - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0391 - val_mse: 0.0391
Epoch 39/100
268/268 - 0s - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0365 - val_mse: 0.0365
Epoch 40/100
268/268 - 0s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0356 - val_mse: 0.0356
Epoch 41/100
268/268 - 0s - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0376 - val_mse: 0.0376
Epoch 42/100
268/268 - 0s - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0365 - val_mse: 0.0365
Epoch 43/100
268/268 - 0s - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0403 - val_mse: 0.0403
Epoch 44/100
268/268 - 0s - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0346 - val_mse: 0.0346
Epoch 45/100
268/268 - 0s - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0361 - val_mse: 0.0361
Epoch 46/100
268/268 - 0s - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0328 - val_mse: 0.0328
Epoch 47/100
268/268 - 0s - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0318 - val_mse: 0.0318
Epoch 48/100
268/268 - 0s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0327 - val_mse: 0.0327
Epoch 49/100
268/268 - 0s - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0320 - val_mse: 0.0320
Epoch 50/100
268/268 - 0s - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0329 - val_mse: 0.0329
Epoch 51/100
268/268 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0323 - val_mse: 0.0323
Epoch 52/100
268/268 - 0s - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0311 - val_mse: 0.0311
Epoch 53/100
268/268 - 0s - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0299 - val_mse: 0.0299
Epoch 54/100
268/268 - 0s - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0292 - val_mse: 0.0292
Epoch 55/100
268/268 - 0s - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0307 - val_mse: 0.0307
Epoch 56/100
268/268 - 0s - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0277 - val_mse: 0.0277
Epoch 57/100
268/268 - 0s - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0304 - val_mse: 0.0304
Epoch 58/100
268/268 - 0s - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0276 - val_mse: 0.0276
Epoch 59/100
268/268 - 0s - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0277 - val_mse: 0.0277
Epoch 60/100
268/268 - 0s - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0280 - val_mse: 0.0280
Epoch 61/100
268/268 - 0s - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0279 - val_mse: 0.0279
Epoch 62/100
268/268 - 0s - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0263 - val_mse: 0.0263
Epoch 63/100
268/268 - 0s - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0261 - val_mse: 0.0261
Epoch 64/100
268/268 - 0s - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0253 - val_mse: 0.0253
Epoch 65/100
268/268 - 0s - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0260 - val_mse: 0.0260
Epoch 66/100
268/268 - 0s - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0256 - val_mse: 0.0256
Epoch 67/100
268/268 - 0s - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 68/100
268/268 - 0s - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0247 - val_mse: 0.0247
Epoch 69/100
268/268 - 0s - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0251 - val_mse: 0.0251
Epoch 70/100
268/268 - 0s - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 71/100
268/268 - 0s - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0250 - val_mse: 0.0250
Epoch 72/100
268/268 - 0s - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0229 - val_mse: 0.0229
Epoch 73/100
268/268 - 0s - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0230 - val_mse: 0.0230
Epoch 74/100
268/268 - 0s - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0229 - val_mse: 0.0229
Epoch 75/100
268/268 - 0s - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0228 - val_mse: 0.0228
Epoch 76/100
268/268 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0228 - val_mse: 0.0228
Epoch 77/100
268/268 - 0s - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 78/100
268/268 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0218 - val_mse: 0.0218
Epoch 79/100
268/268 - 0s - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0223 - val_mse: 0.0223
Epoch 80/100
268/268 - 0s - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0220 - val_mse: 0.0220
Epoch 81/100
268/268 - 0s - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0215 - val_mse: 0.0215
Epoch 82/100
268/268 - 0s - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0216 - val_mse: 0.0216
Epoch 83/100
268/268 - 0s - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0212 - val_mse: 0.0212
Epoch 84/100
268/268 - 0s - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0211 - val_mse: 0.0211
Epoch 85/100
268/268 - 0s - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0207 - val_mse: 0.0207
Epoch 86/100
268/268 - 0s - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0209 - val_mse: 0.0209
Epoch 87/100
268/268 - 0s - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0204 - val_mse: 0.0204
Epoch 88/100
268/268 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0209 - val_mse: 0.0209
Epoch 89/100
268/268 - 0s - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0201 - val_mse: 0.0201
Epoch 90/100
268/268 - 0s - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0207 - val_mse: 0.0207
Epoch 91/100
268/268 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0206 - val_mse: 0.0206
Epoch 92/100
268/268 - 0s - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0204 - val_mse: 0.0204
Epoch 93/100
268/268 - 0s - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0200 - val_mse: 0.0200
Epoch 94/100
268/268 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0201 - val_mse: 0.0201
Epoch 95/100
268/268 - 0s - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0193 - val_mse: 0.0193
Epoch 96/100
268/268 - 0s - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0196 - val_mse: 0.0196
Epoch 97/100
268/268 - 0s - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0199 - val_mse: 0.0199
Epoch 98/100
268/268 - 0s - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0192 - val_mse: 0.0192
Epoch 99/100
268/268 - 0s - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0197 - val_mse: 0.0197
Epoch 100/100
268/268 - 0s - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0196 - val_mse: 0.0196
saving model CNNxySTOCHASTIC10
model 11/120
time elapsed:
00:05:11.70
estimated time left:
00:51:28.68 


STOCHASTIC run: 11
Train on 188 samples, validate on 47 samples
Epoch 1/100
188/188 - 1s - loss: 1.2069 - mse: 1.2069 - val_loss: 1.0223 - val_mse: 1.0223
Epoch 2/100
188/188 - 0s - loss: 0.8862 - mse: 0.8862 - val_loss: 0.6730 - val_mse: 0.6730
Epoch 3/100
188/188 - 0s - loss: 0.5643 - mse: 0.5643 - val_loss: 0.3735 - val_mse: 0.3735
Epoch 4/100
188/188 - 0s - loss: 0.3358 - mse: 0.3358 - val_loss: 0.2335 - val_mse: 0.2335
Epoch 5/100
188/188 - 0s - loss: 0.2440 - mse: 0.2440 - val_loss: 0.1955 - val_mse: 0.1955
Epoch 6/100
188/188 - 0s - loss: 0.2145 - mse: 0.2145 - val_loss: 0.1839 - val_mse: 0.1839
Epoch 7/100
188/188 - 0s - loss: 0.2020 - mse: 0.2020 - val_loss: 0.1821 - val_mse: 0.1821
Epoch 8/100
188/188 - 0s - loss: 0.1952 - mse: 0.1952 - val_loss: 0.1862 - val_mse: 0.1862
Epoch 9/100
188/188 - 0s - loss: 0.1932 - mse: 0.1932 - val_loss: 0.1913 - val_mse: 0.1913
Epoch 10/100
188/188 - 0s - loss: 0.1955 - mse: 0.1955 - val_loss: 0.1971 - val_mse: 0.1971
Epoch 11/100
188/188 - 0s - loss: 0.1975 - mse: 0.1975 - val_loss: 0.1988 - val_mse: 0.1988
Epoch 12/100
188/188 - 0s - loss: 0.1968 - mse: 0.1968 - val_loss: 0.1957 - val_mse: 0.1957
Epoch 13/100
188/188 - 0s - loss: 0.1950 - mse: 0.1950 - val_loss: 0.1951 - val_mse: 0.1951
Epoch 14/100
188/188 - 0s - loss: 0.1914 - mse: 0.1914 - val_loss: 0.1867 - val_mse: 0.1867
Epoch 15/100
188/188 - 0s - loss: 0.1868 - mse: 0.1868 - val_loss: 0.1825 - val_mse: 0.1825
Epoch 16/100
188/188 - 0s - loss: 0.1827 - mse: 0.1827 - val_loss: 0.1770 - val_mse: 0.1770
Epoch 17/100
188/188 - 0s - loss: 0.1781 - mse: 0.1781 - val_loss: 0.1686 - val_mse: 0.1686
Epoch 18/100
188/188 - 0s - loss: 0.1726 - mse: 0.1726 - val_loss: 0.1645 - val_mse: 0.1645
Epoch 19/100
188/188 - 0s - loss: 0.1689 - mse: 0.1689 - val_loss: 0.1578 - val_mse: 0.1578
Epoch 20/100
188/188 - 0s - loss: 0.1639 - mse: 0.1639 - val_loss: 0.1531 - val_mse: 0.1531
Epoch 21/100
188/188 - 0s - loss: 0.1567 - mse: 0.1567 - val_loss: 0.1490 - val_mse: 0.1490
Epoch 22/100
188/188 - 0s - loss: 0.1568 - mse: 0.1568 - val_loss: 0.1453 - val_mse: 0.1453
Epoch 23/100
188/188 - 0s - loss: 0.1538 - mse: 0.1538 - val_loss: 0.1451 - val_mse: 0.1451
Epoch 24/100
188/188 - 0s - loss: 0.1520 - mse: 0.1520 - val_loss: 0.1400 - val_mse: 0.1400
Epoch 25/100
188/188 - 0s - loss: 0.1481 - mse: 0.1481 - val_loss: 0.1382 - val_mse: 0.1382
Epoch 26/100
188/188 - 0s - loss: 0.1460 - mse: 0.1460 - val_loss: 0.1361 - val_mse: 0.1361
Epoch 27/100
188/188 - 0s - loss: 0.1439 - mse: 0.1439 - val_loss: 0.1341 - val_mse: 0.1341
Epoch 28/100
188/188 - 0s - loss: 0.1420 - mse: 0.1420 - val_loss: 0.1323 - val_mse: 0.1323
Epoch 29/100
188/188 - 0s - loss: 0.1406 - mse: 0.1406 - val_loss: 0.1305 - val_mse: 0.1305
Epoch 30/100
188/188 - 0s - loss: 0.1381 - mse: 0.1381 - val_loss: 0.1288 - val_mse: 0.1288
Epoch 31/100
188/188 - 0s - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1285 - val_mse: 0.1285
Epoch 32/100
188/188 - 0s - loss: 0.1355 - mse: 0.1355 - val_loss: 0.1259 - val_mse: 0.1259
Epoch 33/100
188/188 - 0s - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1267 - val_mse: 0.1267
Epoch 34/100
188/188 - 0s - loss: 0.1306 - mse: 0.1306 - val_loss: 0.1234 - val_mse: 0.1234
Epoch 35/100
188/188 - 0s - loss: 0.1283 - mse: 0.1283 - val_loss: 0.1237 - val_mse: 0.1237
Epoch 36/100
188/188 - 0s - loss: 0.1265 - mse: 0.1265 - val_loss: 0.1205 - val_mse: 0.1205
Epoch 37/100
188/188 - 0s - loss: 0.1242 - mse: 0.1242 - val_loss: 0.1196 - val_mse: 0.1196
Epoch 38/100
188/188 - 0s - loss: 0.1222 - mse: 0.1222 - val_loss: 0.1161 - val_mse: 0.1161
Epoch 39/100
188/188 - 0s - loss: 0.1210 - mse: 0.1210 - val_loss: 0.1159 - val_mse: 0.1159
Epoch 40/100
188/188 - 0s - loss: 0.1188 - mse: 0.1188 - val_loss: 0.1160 - val_mse: 0.1160
Epoch 41/100
188/188 - 0s - loss: 0.1166 - mse: 0.1166 - val_loss: 0.1133 - val_mse: 0.1133
Epoch 42/100
188/188 - 0s - loss: 0.1155 - mse: 0.1155 - val_loss: 0.1120 - val_mse: 0.1120
Epoch 43/100
188/188 - 0s - loss: 0.1131 - mse: 0.1131 - val_loss: 0.1092 - val_mse: 0.1092
Epoch 44/100
188/188 - 0s - loss: 0.1115 - mse: 0.1115 - val_loss: 0.1095 - val_mse: 0.1095
Epoch 45/100
188/188 - 0s - loss: 0.1100 - mse: 0.1100 - val_loss: 0.1087 - val_mse: 0.1087
Epoch 46/100
188/188 - 0s - loss: 0.1081 - mse: 0.1081 - val_loss: 0.1065 - val_mse: 0.1065
Epoch 47/100
188/188 - 0s - loss: 0.1066 - mse: 0.1066 - val_loss: 0.1058 - val_mse: 0.1058
Epoch 48/100
188/188 - 0s - loss: 0.1050 - mse: 0.1050 - val_loss: 0.1026 - val_mse: 0.1026
Epoch 49/100
188/188 - 0s - loss: 0.1033 - mse: 0.1033 - val_loss: 0.1036 - val_mse: 0.1036
Epoch 50/100
188/188 - 0s - loss: 0.1015 - mse: 0.1015 - val_loss: 0.1016 - val_mse: 0.1016
Epoch 51/100
188/188 - 0s - loss: 0.0999 - mse: 0.0999 - val_loss: 0.1001 - val_mse: 0.1001
Epoch 52/100
188/188 - 0s - loss: 0.0982 - mse: 0.0982 - val_loss: 0.0990 - val_mse: 0.0990
Epoch 53/100
188/188 - 0s - loss: 0.0970 - mse: 0.0970 - val_loss: 0.0969 - val_mse: 0.0969
Epoch 54/100
188/188 - 0s - loss: 0.0955 - mse: 0.0955 - val_loss: 0.0966 - val_mse: 0.0966
Epoch 55/100
188/188 - 0s - loss: 0.0940 - mse: 0.0940 - val_loss: 0.0962 - val_mse: 0.0962
Epoch 56/100
188/188 - 0s - loss: 0.0927 - mse: 0.0927 - val_loss: 0.0947 - val_mse: 0.0947
Epoch 57/100
188/188 - 0s - loss: 0.0914 - mse: 0.0914 - val_loss: 0.0941 - val_mse: 0.0941
Epoch 58/100
188/188 - 0s - loss: 0.0901 - mse: 0.0901 - val_loss: 0.0935 - val_mse: 0.0935
Epoch 59/100
188/188 - 0s - loss: 0.0889 - mse: 0.0889 - val_loss: 0.0921 - val_mse: 0.0921
Epoch 60/100
188/188 - 0s - loss: 0.0876 - mse: 0.0876 - val_loss: 0.0923 - val_mse: 0.0923
Epoch 61/100
188/188 - 0s - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0913 - val_mse: 0.0913
Epoch 62/100
188/188 - 0s - loss: 0.0852 - mse: 0.0852 - val_loss: 0.0901 - val_mse: 0.0901
Epoch 63/100
188/188 - 0s - loss: 0.0842 - mse: 0.0842 - val_loss: 0.0903 - val_mse: 0.0903
Epoch 64/100
188/188 - 0s - loss: 0.0830 - mse: 0.0830 - val_loss: 0.0897 - val_mse: 0.0897
Epoch 65/100
188/188 - 0s - loss: 0.0819 - mse: 0.0819 - val_loss: 0.0881 - val_mse: 0.0881
Epoch 66/100
188/188 - 0s - loss: 0.0811 - mse: 0.0811 - val_loss: 0.0882 - val_mse: 0.0882
Epoch 67/100
188/188 - 0s - loss: 0.0797 - mse: 0.0797 - val_loss: 0.0878 - val_mse: 0.0878
Epoch 68/100
188/188 - 0s - loss: 0.0789 - mse: 0.0789 - val_loss: 0.0858 - val_mse: 0.0858
Epoch 69/100
188/188 - 0s - loss: 0.0777 - mse: 0.0777 - val_loss: 0.0867 - val_mse: 0.0867
Epoch 70/100
188/188 - 0s - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0848 - val_mse: 0.0848
Epoch 71/100
188/188 - 0s - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0871 - val_mse: 0.0871
Epoch 72/100
188/188 - 0s - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0831 - val_mse: 0.0831
Epoch 73/100
188/188 - 0s - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0853 - val_mse: 0.0853
Epoch 74/100
188/188 - 0s - loss: 0.0730 - mse: 0.0730 - val_loss: 0.0834 - val_mse: 0.0834
Epoch 75/100
188/188 - 0s - loss: 0.0723 - mse: 0.0723 - val_loss: 0.0839 - val_mse: 0.0839
Epoch 76/100
188/188 - 0s - loss: 0.0712 - mse: 0.0712 - val_loss: 0.0818 - val_mse: 0.0818
Epoch 77/100
188/188 - 0s - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0800 - val_mse: 0.0800
Epoch 78/100
188/188 - 0s - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0820 - val_mse: 0.0820
Epoch 79/100
188/188 - 0s - loss: 0.0687 - mse: 0.0687 - val_loss: 0.0810 - val_mse: 0.0810
Epoch 80/100
188/188 - 0s - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0805 - val_mse: 0.0805
Epoch 81/100
188/188 - 0s - loss: 0.0668 - mse: 0.0668 - val_loss: 0.0780 - val_mse: 0.0780
Epoch 82/100
188/188 - 0s - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0806 - val_mse: 0.0806
Epoch 83/100
188/188 - 0s - loss: 0.0653 - mse: 0.0653 - val_loss: 0.0792 - val_mse: 0.0792
Epoch 84/100
188/188 - 0s - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0792 - val_mse: 0.0792
Epoch 85/100
188/188 - 0s - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0784 - val_mse: 0.0784
Epoch 86/100
188/188 - 0s - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0797 - val_mse: 0.0797
Epoch 87/100
188/188 - 0s - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0786 - val_mse: 0.0786
Epoch 88/100
188/188 - 0s - loss: 0.0614 - mse: 0.0614 - val_loss: 0.0781 - val_mse: 0.0781
Epoch 89/100
188/188 - 0s - loss: 0.0606 - mse: 0.0606 - val_loss: 0.0780 - val_mse: 0.0780
Epoch 90/100
188/188 - 0s - loss: 0.0596 - mse: 0.0596 - val_loss: 0.0771 - val_mse: 0.0771
Epoch 91/100
188/188 - 0s - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0782 - val_mse: 0.0782
Epoch 92/100
188/188 - 0s - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0769 - val_mse: 0.0769
Epoch 93/100
188/188 - 0s - loss: 0.0572 - mse: 0.0572 - val_loss: 0.0768 - val_mse: 0.0768
Epoch 94/100
188/188 - 0s - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0773 - val_mse: 0.0773
Epoch 95/100
188/188 - 0s - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0775 - val_mse: 0.0775
Epoch 96/100
188/188 - 0s - loss: 0.0548 - mse: 0.0548 - val_loss: 0.0777 - val_mse: 0.0777
Epoch 97/100
188/188 - 0s - loss: 0.0541 - mse: 0.0541 - val_loss: 0.0763 - val_mse: 0.0763
Epoch 98/100
188/188 - 0s - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0762 - val_mse: 0.0762
Epoch 99/100
188/188 - 0s - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0770 - val_mse: 0.0770
Epoch 100/100
188/188 - 0s - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0762 - val_mse: 0.0762
saving model CNNxySTOCHASTIC11
model 12/120
time elapsed:
00:05:24.86
estimated time left:
00:48:43.75 


STOCHASTIC run: 12
Train on 108 samples, validate on 27 samples
Epoch 1/100
108/108 - 1s - loss: 0.4116 - mse: 0.4116 - val_loss: 0.3094 - val_mse: 0.3094
Epoch 2/100
108/108 - 0s - loss: 0.2968 - mse: 0.2968 - val_loss: 0.2174 - val_mse: 0.2174
Epoch 3/100
108/108 - 0s - loss: 0.2141 - mse: 0.2141 - val_loss: 0.1889 - val_mse: 0.1889
Epoch 4/100
108/108 - 0s - loss: 0.1910 - mse: 0.1910 - val_loss: 0.2174 - val_mse: 0.2174
Epoch 5/100
108/108 - 0s - loss: 0.2055 - mse: 0.2055 - val_loss: 0.2386 - val_mse: 0.2386
Epoch 6/100
108/108 - 0s - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2392 - val_mse: 0.2392
Epoch 7/100
108/108 - 0s - loss: 0.2010 - mse: 0.2010 - val_loss: 0.2289 - val_mse: 0.2289
Epoch 8/100
108/108 - 0s - loss: 0.1890 - mse: 0.1890 - val_loss: 0.2189 - val_mse: 0.2189
Epoch 9/100
108/108 - 0s - loss: 0.1800 - mse: 0.1800 - val_loss: 0.2122 - val_mse: 0.2122
Epoch 10/100
108/108 - 0s - loss: 0.1764 - mse: 0.1764 - val_loss: 0.2032 - val_mse: 0.2032
Epoch 11/100
108/108 - 0s - loss: 0.1714 - mse: 0.1714 - val_loss: 0.1903 - val_mse: 0.1903
Epoch 12/100
108/108 - 0s - loss: 0.1631 - mse: 0.1631 - val_loss: 0.1749 - val_mse: 0.1749
Epoch 13/100
108/108 - 0s - loss: 0.1537 - mse: 0.1537 - val_loss: 0.1611 - val_mse: 0.1611
Epoch 14/100
108/108 - 0s - loss: 0.1431 - mse: 0.1431 - val_loss: 0.1528 - val_mse: 0.1528
Epoch 15/100
108/108 - 0s - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1517 - val_mse: 0.1517
Epoch 16/100
108/108 - 0s - loss: 0.1191 - mse: 0.1191 - val_loss: 0.1482 - val_mse: 0.1482
Epoch 17/100
108/108 - 0s - loss: 0.1098 - mse: 0.1098 - val_loss: 0.1377 - val_mse: 0.1377
Epoch 18/100
108/108 - 0s - loss: 0.1057 - mse: 0.1057 - val_loss: 0.1351 - val_mse: 0.1351
Epoch 19/100
108/108 - 0s - loss: 0.1009 - mse: 0.1009 - val_loss: 0.1355 - val_mse: 0.1355
Epoch 20/100
108/108 - 0s - loss: 0.0955 - mse: 0.0955 - val_loss: 0.1251 - val_mse: 0.1251
Epoch 21/100
108/108 - 0s - loss: 0.0924 - mse: 0.0924 - val_loss: 0.1158 - val_mse: 0.1158
Epoch 22/100
108/108 - 0s - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1079 - val_mse: 0.1079
Epoch 23/100
108/108 - 0s - loss: 0.0812 - mse: 0.0812 - val_loss: 0.1131 - val_mse: 0.1131
Epoch 24/100
108/108 - 0s - loss: 0.0759 - mse: 0.0759 - val_loss: 0.1042 - val_mse: 0.1042
Epoch 25/100
108/108 - 0s - loss: 0.0671 - mse: 0.0671 - val_loss: 0.0861 - val_mse: 0.0861
Epoch 26/100
108/108 - 0s - loss: 0.0626 - mse: 0.0626 - val_loss: 0.0796 - val_mse: 0.0796
Epoch 27/100
108/108 - 0s - loss: 0.0567 - mse: 0.0567 - val_loss: 0.0849 - val_mse: 0.0849
Epoch 28/100
108/108 - 0s - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0819 - val_mse: 0.0819
Epoch 29/100
108/108 - 0s - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0720 - val_mse: 0.0720
Epoch 30/100
108/108 - 0s - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0695 - val_mse: 0.0695
Epoch 31/100
108/108 - 0s - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0713 - val_mse: 0.0713
Epoch 32/100
108/108 - 0s - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0754 - val_mse: 0.0754
Epoch 33/100
108/108 - 0s - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0682 - val_mse: 0.0682
Epoch 34/100
108/108 - 0s - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0693 - val_mse: 0.0693
Epoch 35/100
108/108 - 0s - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0772 - val_mse: 0.0772
Epoch 36/100
108/108 - 0s - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0728 - val_mse: 0.0728
Epoch 37/100
108/108 - 0s - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0656 - val_mse: 0.0656
Epoch 38/100
108/108 - 0s - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0678 - val_mse: 0.0678
Epoch 39/100
108/108 - 0s - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0774 - val_mse: 0.0774
Epoch 40/100
108/108 - 0s - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0741 - val_mse: 0.0741
Epoch 41/100
108/108 - 0s - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0606 - val_mse: 0.0606
Epoch 42/100
108/108 - 0s - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0631 - val_mse: 0.0631
Epoch 43/100
108/108 - 0s - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0769 - val_mse: 0.0769
Epoch 44/100
108/108 - 0s - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0672 - val_mse: 0.0672
Epoch 45/100
108/108 - 0s - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0589 - val_mse: 0.0589
Epoch 46/100
108/108 - 0s - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0619 - val_mse: 0.0619
Epoch 47/100
108/108 - 0s - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0637 - val_mse: 0.0637
Epoch 48/100
108/108 - 0s - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0602 - val_mse: 0.0602
Epoch 49/100
108/108 - 0s - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0607 - val_mse: 0.0607
Epoch 50/100
108/108 - 0s - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0601 - val_mse: 0.0601
Epoch 51/100
108/108 - 0s - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0622 - val_mse: 0.0622
Epoch 52/100
108/108 - 0s - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0632 - val_mse: 0.0632
Epoch 53/100
108/108 - 0s - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0601 - val_mse: 0.0601
Epoch 54/100
108/108 - 0s - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0606 - val_mse: 0.0606
Epoch 55/100
108/108 - 0s - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0631 - val_mse: 0.0631
saving model CNNxySTOCHASTIC12
model 13/120
time elapsed:
00:05:30.12
estimated time left:
00:45:17.17 


STOCHASTIC run: 13
Train on 28 samples, validate on 7 samples
Epoch 1/100
28/28 - 1s - loss: 0.3022 - mse: 0.3022 - val_loss: 0.2964 - val_mse: 0.2964
Epoch 2/100
28/28 - 0s - loss: 0.2731 - mse: 0.2731 - val_loss: 0.2640 - val_mse: 0.2640
Epoch 3/100
28/28 - 0s - loss: 0.2469 - mse: 0.2469 - val_loss: 0.2342 - val_mse: 0.2342
Epoch 4/100
28/28 - 0s - loss: 0.2237 - mse: 0.2237 - val_loss: 0.2079 - val_mse: 0.2079
Epoch 5/100
28/28 - 0s - loss: 0.2042 - mse: 0.2042 - val_loss: 0.1865 - val_mse: 0.1865
Epoch 6/100
28/28 - 0s - loss: 0.1894 - mse: 0.1894 - val_loss: 0.1712 - val_mse: 0.1712
Epoch 7/100
28/28 - 0s - loss: 0.1802 - mse: 0.1802 - val_loss: 0.1629 - val_mse: 0.1629
Epoch 8/100
28/28 - 0s - loss: 0.1770 - mse: 0.1770 - val_loss: 0.1610 - val_mse: 0.1610
Epoch 9/100
28/28 - 0s - loss: 0.1785 - mse: 0.1785 - val_loss: 0.1629 - val_mse: 0.1629
Epoch 10/100
28/28 - 0s - loss: 0.1816 - mse: 0.1816 - val_loss: 0.1657 - val_mse: 0.1657
Epoch 11/100
28/28 - 0s - loss: 0.1835 - mse: 0.1835 - val_loss: 0.1679 - val_mse: 0.1679
Epoch 12/100
28/28 - 0s - loss: 0.1835 - mse: 0.1835 - val_loss: 0.1693 - val_mse: 0.1693
Epoch 13/100
28/28 - 0s - loss: 0.1818 - mse: 0.1818 - val_loss: 0.1700 - val_mse: 0.1700
Epoch 14/100
28/28 - 0s - loss: 0.1792 - mse: 0.1792 - val_loss: 0.1703 - val_mse: 0.1703
Epoch 15/100
28/28 - 0s - loss: 0.1763 - mse: 0.1763 - val_loss: 0.1705 - val_mse: 0.1705
Epoch 16/100
28/28 - 0s - loss: 0.1736 - mse: 0.1736 - val_loss: 0.1706 - val_mse: 0.1706
Epoch 17/100
28/28 - 0s - loss: 0.1713 - mse: 0.1713 - val_loss: 0.1703 - val_mse: 0.1703
Epoch 18/100
28/28 - 0s - loss: 0.1691 - mse: 0.1691 - val_loss: 0.1695 - val_mse: 0.1695
saving model CNNxySTOCHASTIC13
model 14/120
time elapsed:
00:05:32.12
estimated time left:
00:41:54.59 


STOCHASTIC run: 14
Traceback (most recent call last):
  File "train_models.py", line 255, in <module>
    run_experiments()
  File "train_models.py", line 205, in run_experiments
    model = build_model_xy(images[0].shape)
IndexError: index 0 is out of bounds for axis 0 with size 0


###############################################################################
Peregrine Cluster
Job 20848970 for user 'f118885'
Finished at: Thu Jul  1 10:07:16 CEST 2021

Job details:
============

Job ID              : 20848970
Name                : CNN_job
User                : f118885
Partition           : gpu
Nodes               : pg-gpu29
Number of Nodes     : 1
Cores               : 12
State               : FAILED
Submit              : 2021-07-01T09:11:53
Start               : 2021-07-01T10:01:32
End                 : 2021-07-01T10:07:16
Reserved walltime   : 00:10:00
Used walltime       : 00:05:44
Used CPU time       : 00:11:01 (efficiency: 16.03%)
% User (Computation): 93.13%
% System (I/O)      :  6.87%
Mem reserved        : 40G/node
Max Mem used        : 7.32G (pg-gpu29)
Max Disk Write      : 122.88K (pg-gpu29)
Max Disk Read       : 3.20M (pg-gpu29)
Average GPU usage   : 48.3% (pg-gpu29)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/introduction/scientific_output

################################################################################
