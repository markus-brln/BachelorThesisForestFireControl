Different levels of difficulty:

NOTE:
Comparing the amount of cells conserved may be useless because
all architectures will learn from the same data. We could only
employ additional algorithms to dig closer to the fire etc.
The main difference between the algorithms would be how well
they generalize for different environments, in my estimation.

1. BASIC [WORKS]
setting:
- 5 agents, static spawning in regular distance (star formation), 70 agent radius,
- fire_step_multiplicator = 0.3 => 2 pixels per 20, so 1/10 of agent speed digging
- no wind
tactic:
- all digging, close circle, then go outwards still digging
files:
- mEASYFIVE.npy

2. STOCHASTIC [WORKS mostly]
setting:
- same as 1., just agent spawn uncertainty = 10 cells
tactic:
- same as 1.
files:
- mEASYFIVESTOCHASTIC0.npy, mEASYFIVESTOCHASTIC1.npy, mEASYFIVESTOCHASTIC2.npy

3. WIND
setting:
- 8 different wind directions, 5 wind speed levels
- spawn uncertainty = 10
- fire_step_multiplicator = 0.6
  -> max wind speed: 7.6 pixels per 20 timesteps -> 1/2.5 agent speed
  -> min wind speed: 3.6                         -> 1/5.5 agent speed
tactic:
- focus on where the wind is going
files:

4. HIGH SPAWN UNCERTAINTY
setting:
- higher spawn uncertainty, not
tactic:
-
files:

4. HIGH SPAWN UNCERTAINTY + WIND
setting:
- difficulties of 3. and 4. combined
tactic:
-
files:

- maybe first experiment is too trivial
- 3 architectures * 4 experiments * 10(?) trained models each